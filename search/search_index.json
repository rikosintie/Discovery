{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-network-discovery-repository","title":"Welcome to the Network Discovery Repository","text":"<p>Let's dig for some network gold!</p> <p></p> <p>The full documentation including installation instructions can be found on my GitHub Pages Repository</p>"},{"location":"#asciinema-video","title":"ASCIINEMA video","text":"<p>Here is an asciinema video that shows the script running. In the video there are switches that have:</p> <ul> <li>ssh V1 which isn't supported</li> <li>a switch that didn't accept the credentials given</li> <li>a switch that didn't respond</li> </ul> <p>The script notes these issues, saves the <code>hostname, ip address, reason</code> to a file. It then moves onto the next device.</p> <p>If you use the terminal daily, I highly recommend checking out ascinema. It's an open source tool that lets you:</p> <p>\"Record and share your terminal sessions, the simple way. Forget screen recording apps and blurry video. Experience a lightweight, text-based approach to terminal recording.\"</p>"},{"location":"#netdevops-resources","title":"NetDevOps Resources","text":"<p>If you are getting into NetDevOps, I have a few resources that you might find useful:</p> <ul> <li>Ubuntu for Network Engineers - A guide for anyone that wants to learn Ubuntu and Network Engineering</li> <li>Cisco DevNetAssociate - Some of the materials I found useful for the Cisco NetDev Associate certification</li> <li>Juniper Migrating to JunOS from Cisco - Some of the materials I used to pass the JCNIA certification exam.</li> <li>Juniper DevOps Materials to study for the Juniper DevOps certification</li> <li>Networking Cook Book - Some configuration snippets for Cisco, Aruba CX and HPE Procurve switches.</li> </ul>"},{"location":"Getting_Started/","title":"Getting Started","text":"<p>The scripts run on Mac/Linux/Windows! It took some effort to get all the paths and other details working across all three platforms but it was worth the effort in the end! You do not need any prior python programming experience to use them. The instructions below will walk you through step by step how to install Python, the Python Virtual Environment, the required libraries and activating the python virtual environment.</p> <ul> <li>Clone the repository from GitHub</li> <li>Create a Python Virtual Environment</li> <li>Activate the Python Virtual Environment</li> <li>Install dependencies</li> <li>Deactivate the Python Virtual Environment</li> </ul> <p>Let's get started!</p>"},{"location":"Getting_Started/#0-install-python-if-you-need-it","title":"0. Install Python if you need it","text":"<p>Python is a popular programming language for Network Development Operations (NetDevOps). It's well worth the time to install Python and learn the basics of running Python scripts.</p>"},{"location":"Getting_Started/#windows-10-and-windows-11","title":"Windows 10 and Windows 11","text":"<p>If you haven't done any  Python development on your Windows machine it doesn't have Python or Git installed. Python is the language the scripts are written in and Git is the industry standard version control system for NetDevOps. Follow the instructions below to install both packages.</p> <p>Note</p> <p>From docs.python.org Unlike most Unix systems and services, Windows does not include a system supported installation of Python. To make Python available, the CPython team has compiled Windows installers with every release for many years. These installers are primarily intended to add a per-user installation of Python, with the core interpreter and library being used by a single user.</p> <p>Installing Python on Windows is simple.</p> <ul> <li>click the start menu</li> <li>Type <code>microsoft store</code> and press <code>enter</code></li> <li>search for <code>python 3.12</code></li> <li>Click on the <code>Free</code> button</li> <li>click on <code>Get</code></li> </ul> <p></p> <p>One advantage of installing Python on Windows is the installer installs Python, pip and the Python Virtual environment <code>venv</code>. You can use <code>where python</code> from cmd.exe to verify that Python is installed.</p> <pre><code>where python\nC:\\Users\\mhubbard\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n</code></pre> <p>You can also use the GUI tool <code>Add or Remove Programs</code> to verify Python is installed:</p> <p></p>"},{"location":"Getting_Started/#test-the-installation-on-windows","title":"Test the installation on Windows","text":"<pre><code>python\n</code></pre> <p>You should see something like this:</p> <pre><code>Python 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n</code></pre> <p>To quit Python, type:</p> <pre><code>quit()\n</code></pre>"},{"location":"Getting_Started/#install-git","title":"Install Git","text":"<p>If you are on Windows and don't have git installed, use</p> <pre><code>winget install --id Git.Git -e --source winget\n</code></pre> <p>from cmd or PowerShell to install Git.</p> <p>WinGet, also known as the Windows Package Manager, is pre-installed on Windows 11 versions 21H2 and later. If you don't have <code>winget</code> installed, you can install it using these steps:</p> <ul> <li>Type <code>microsoft store</code> in the Windows search bar, press <code>enter</code></li> <li>Search for <code>App Installer</code></li> <li>Click on <code>Get</code></li> </ul> <p>Or you can install the <code>git</code> package from The Official Git Page. It seems better to use the Microsoft Store but I'm not a Windows expert.</p>"},{"location":"Getting_Started/#macos","title":"macOS","text":"<p>Apple provides a package called <code>xcode-select</code> full of developer tools like <code>Python</code>, <code>git</code>, and <code>gcc</code> (Gnu C Compiler), etc. To install <code>xcode-select</code></p> <ul> <li>Open a terminal</li> <li>Type <code>xcode-select --install</code>, press <code>enter</code></li> </ul> <p>You can list the tools using</p> <pre><code>ls /Library/Developer/CommandLineTools/usr/bin/`\n</code></pre> <p>You now have <code>Python</code>, <code>git</code>, <code>venv</code> and many other dev tools.</p>"},{"location":"Getting_Started/#ubuntu-2404-or-higher","title":"Ubuntu 24.04 or higher","text":"<p>If you are on a brand new install of Ubuntu and haven't done any python coding you will need to install the Python <code>venv</code> and <code>pip</code> libraries before creating the virtual environment. We need to know what version of python you have installed. From a terminal, run the following:</p> <pre><code>which python3\n/usr/bin/python3\nls -l /usr/bin/python3\nlrwxrwxrwx - root  7 Aug  2024 \uf016 /usr/bin/python3 -&gt; python3.12\n</code></pre> <p>Python 3.12 is what my new Ubuntu 24.04 VM has installed. Run the following, replace <code>3.12</code> with your Python version.</p> <pre><code>sudo apt install python3.12-venv  &amp;&amp; sudo apt install python3-pip\n</code></pre> <p>This will install the Python virtual environment library and pip, the \u202fofficial package installer for Python. The <code>&amp;&amp;</code> means run the second command only if the first succeeds.</p>"},{"location":"Getting_Started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>All of the installation steps are done in the Mac/Linux terminal or cmd.exe/PowerShell on Windows. In my recent testing on Windows 11 24H2, I learned a lot about PowerShell on Windows 11. I created a page on what my setup looks like. I highly recommend installing the Windows Terminal and setting up PowerShell if you are a Windows user. Here is a link to the page - Using PowerShell with the Network Discovery scripts. PowerShell is also available on Mac/Linux. The configurations on the <code>Using Powershell</code> page work on all three OSes.</p> <p>Open the Mac/Linux terminal or cmd/PowerShell and paste the following:</p> <pre><code>git clone https://github.com/rikosintie/Discovery.git\ncd Discovery\n</code></pre> <p>If you don't want to install Git</p> <p>If you don't want to install git, you can download a zip file from the Network Discovery repository. Click on the green \"Code\" button and select \"Download ZIP\". Then unzip the file and cd into the <code>Discovery</code> directory.</p> <p></p> <p>I recommend installing Git. I make updates to the project and if you have git installed you can simply run <code>git pull</code> to pull down the latest version. Also, there are thousands of projects on GitHub.com and GitLab.com. Once you get comfortable with <code>git</code> you will have access to a lot of tools! You can install git from The official Git page.</p> <p>If you plan to modify the python scripts then this won't work because your versions will be different than the repo and git will not allow you to overwrite. In that case, open a Pull Request on the repo and I'll see if I can accept your changes!</p> <p>Info</p> <p>Once you have the repository cloned it is linked to the repository on github.com. You should issue a <code>git pull</code> from the terminal once in a while to pull down any changes that have been made to the repository.</p>"},{"location":"Getting_Started/#2-using-a-python-virtual-environment","title":"2. Using a Python Virtual Environment","text":"<p>I recommend running the scripts in a Python Virtual environment, especially if you on Mac/Linux. Both Operating systems use Python to manage system resources. macOS will usually stop you from installing into the system Python folder but Ubuntu may not. It is possible to break your system if you upgrade system level packages.</p> <p>Using a virtual environment eliminates that risk.</p>"},{"location":"Getting_Started/#create-the-python-virtual-environment","title":"Create the Python Virtual Environment","text":"<p><code>python -m venv venv --upgrade-deps --prompt=\"Discovery\"</code></p> <p>This will create the standard \"venv\" directory but when activated will display \"Discovery\". I prefer this over using <code>python -m venv Discovery</code> because it's the standard way to create the virtual environment. But I like seeing Discovery instead of venv when I activate the environment.</p> <p>The <code>--upgrade-deps</code> argument tells python to upgrade pip to the latest version when creating the virtual environment. You need internet access for pip to be upgraded. If you don't have internet access, remove the <code>--upgrade-deps</code> argument.</p> <p>Windows 11 24h2 issues</p> <p>I developed the script on a Windows 11 22h1 laptop. On June 29, 2025 I cloned the repo to a Windows 11 24h2 laptop to demo for a friend and nothing worked! For some reason, Windows 11 24h2 installs Python 13.1 which is bleeding edge and several of the libraries I use haven't been updated to work with 13.1.</p> <p>To resolve the issue, I installed Python 3.12 from the Windows store using:</p> <pre><code>start menu, microsoft store, python 3.12\nGet\n</code></pre> <p>Then I used <code>python3.12 -m venv venv --upgrade-deps --prompt=\"Discovery\"</code> to successfully install the script with Python 3.12.</p>"},{"location":"Getting_Started/#3-activate-the-virtual-environment","title":"3. Activate the Virtual Environment","text":""},{"location":"Getting_Started/#on-windows-11","title":"On Windows 11","text":"<p><code>.\\venv\\Scripts\\activate</code></p> <p>Verify that python is in the venv folder:</p> <pre><code>where python\nC:\\Users\\mhubbard.PU\\Documents\\04_tools\\Discovery\\venv\\Scripts\\python.exe\n</code></pre>"},{"location":"Getting_Started/#on-wsl","title":"On WSL","text":"<p>When the Windows install initially failed, I asked ChatGPT what to do and it recommended installing WSL2, Ubuntu 24.04 and running the script in Linux. I did that and everything worked correctly by following the <code>Linux</code> steps below. The WSL terminal NATs to your laptop so you will be using a 172.16.122.x address but everything worked. For NetDevOps, Linux is more popular than Windows, WSL gives you Linux on Windows!</p>"},{"location":"Getting_Started/#navigating-in-wsl","title":"Navigating in WSL","text":"<p>If you haven't used Linux before, navigating the WSL terminal paths will be a learning experience. ChatGPT wrote this function that makes it easier to navigate:</p> <p>From the WSL Ubuntu terminal, open the BASH configuration file using - <code>nano ~/bashrc</code>, go to the bottom of the file and paste in the two lines below.</p> <pre><code># Function to convert windows paths to Linux format\n wincd () { cd $(wslpath $1); }\n</code></pre> <p>Type <code>ctrl+x</code> to exit nano, select y to <code>Save modified buffer?</code></p> <p>Type <code>exec bash</code> to reload the shell.</p> <p>Then use it like:</p> <p>`wincd 'c:\\Users\\mhubbard\\Documents\\Discovery'</p> <p>The command will take you to the WSL <code>/mnt/c/Users/mhubbard/Documents/Discovery</code> folder.</p> <p>I prefer to use zsh as my shell on Mac/Linux with the Oh My Zsh package installed. If you continue to use WSL I recommend that you look at my guide to setting up the Ubuntu terminal. The guide is chalked full of Ubuntu goodness.</p>"},{"location":"Getting_Started/#on-macoslinux","title":"On macOS/Linux","text":"<p><code>source venv/bin/activate</code></p>"},{"location":"Getting_Started/#verify-that-python-is-installed-in-the-venv","title":"Verify that Python is installed in the venv","text":"<p>From the folder that you installed the Project in, run</p> <pre><code>which python3\n</code></pre> <p>You should see a path pointing to the Discovery folder, then venv/bin/python3. On my machine that is <code>/home/mhubbard/04_tools/Discovery/venv/bin/python3</code></p>"},{"location":"Getting_Started/#4-install-dependencies","title":"4. Install Dependencies","text":"<p>You can use <code>pip list</code> to list the packages currently installed. If you run it now you will see:</p> <pre><code>$ pip list\nPackage    Version\n---------- -------\npip        23.3.2\nsetuptools 69.0.3\n</code></pre> <p>Now run the following:</p> <p><code>pip install -r requirements.txt</code></p> <p>You will see all the dependencies being downloaded and installed. Here is a snippet of the dependencies.</p> <pre><code>$ pip install -r requirements.txt\nCollecting asttokens~=2.4.1 (from -r requirements.txt (line 1))\n  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\nCollecting bcrypt~=4.1.2 (from -r requirements.txt (line 2))\n  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n</code></pre> <p>Now if we run <code>pip list</code> we will see that the dependencies have been installed:</p> <pre><code>$ pip list\nPackage       Version\n------------- -------\nasttokens     2.4.1\nbcrypt        4.1.2\ncffi          1.16.0\ncolorama      0.4.6\ncryptography  41.0.7\nexecuting     2.0.1\nfuture        0.18.3\nicecream      2.1.3\nnetmiko       4.3.0\nntc_templates 4.1.0\nparamiko      3.4.0\npip           23.3.2\nprettytable   3.9.0\npycparser     2.21\nPygments      2.17.2\nPyNaCl        1.5.0\npyserial      3.5\nPyYAML        6.0.1\nscp           0.14.5\nsetuptools    69.0.3\nsix           1.16.0\ntextfsm       1.1.3\nwcwidth       0.2.12\n</code></pre>"},{"location":"Getting_Started/#5-deactivate-the-virtual-environment","title":"5. Deactivate the Virtual Environment","text":"<p>When you are finished, deactivate the environment</p> <p><code>deactivate</code></p> <p>You will need to activate the virtual environment each time you want to run the scripts.</p>"},{"location":"Helper-scripts/","title":"The Helper Scripts","text":"<p>The helper scripts are a collection of python scripts that read data that the config_pull.py created and turn that raw data into useful reports.</p>"},{"location":"Helper-scripts/#what-files-are-created","title":"What files are created","text":"<p>After the <code>config_pull.py</code> script finishes, you can use the hostname-CR-data.txt files to get started planning. The script also creates JSON files for:</p> <ul> <li>Port Maps</li> <li>cdp neighbors</li> <li>lldp neighbors</li> <li>system data</li> <li>interface statistics</li> <li>interface mac addresses</li> </ul> <p>In the data folder, below the port-maps folder, two text files are created:</p> <ul> <li>hostname-mac-address.txt - Output of show mac-address per port</li> <li>hostname-arp.txt - Output of show arp command</li> </ul> <p>In the final folder</p> <ul> <li>hostname-ports.txt - The final output of two scripts for creating port maps</li> </ul> <p>In the \"Interface\" folder</p> <ul> <li>hostname-cdp.txt - JSON format of the \"show cdp ne det\" command</li> <li>hostname-lldp.txt - JSON format of \"show lldp info rem det\" command</li> <li>hostname-system.txt - JSON format of \"show system\" command</li> <li>hostname-interface.txt - JSON format of \"show interface\"</li> <li>hostname-int-br.txt - JSON format of \"show interface int br\" command</li> </ul> <p>This section will discuss the scripts that convert the JSON into reports.</p> <p>In addition, there is a script to convert mac addresses between different formats</p> <ul> <li><code>convert-mac.py</code></li> </ul>"},{"location":"Helper-scripts/#creating-port-maps","title":"Creating Port maps","text":"<p>There are two scripts in the discovery folder:</p> <ul> <li>procurve-arp.py - converts the IP and Arp records into \"key\": \"value\" pairs</li> </ul> <p>Here is an example:</p> <pre><code>{\n    \"04d590-0e77ab\": \"10.1.0.252\",\n    \"883a30-76ce00\": \"10.154.1.3\",\n    \"104f58-682100\": \"10.154.1.4\",\n    \"b8d4e7-4c4900\": \"10.154.1.5\",\n}\n</code></pre> <p>The Mac Address is used for the key since MACs are unique, the IP Address is used for the value. It saves the data to hostname-Mac2IP.json in the data folder.</p> <ul> <li>procurve-macaddr.py - Matches the Mac address in the hostname-Mac2IP.json file to the mac address in the hostname-mac-address.txt file.</li> </ul> <p>The port maps return:</p> <ul> <li>Vlan ID</li> <li>IP Address</li> <li>MAC Address</li> <li>Interface</li> <li>Vendor ID</li> </ul> <p>Here is an example of the port map:</p> <pre><code>Number of Entries: 83\n\nDevice Name: Test-Core\nVlan   IP Address       MAC Address       Interface   Vendor\n--------------------------------------------------------------------------------\n   1   10.154.66.1      7c0507-1f6ee4         C1      Pegatron\n----------------------------------------------------------------------\n   1   10.154.66.2      7c0507-1b45ea         C2      Pegatron\n----------------------------------------------------------------------\n   1   10.154.68.25     00c0b7-e4b43a         C4      American\n----------------------------------------------------------------------\n  75   10.154.23.241    000c29-e97dd1         C5      VMware\n----------------------------------------------------------------------\n</code></pre> <p>Having this information makes identifying special devices such as HVAC controllers, Door access controllers, Cameras, etc. easier. It also allows you to verify that all devices are patched back into the correct port on the switch.</p>"},{"location":"Helper-scripts/#running-the-port-map-scripts","title":"Running the port map scripts","text":"<p>There are two general categories of switch deployments. The first is a distributed layer 3 deployment where every closet has a layer 3 router. In that case, the procurve-Config-pull has created an arp.txt file and mac-address.txt file for every switch and the script reads the same inventory file and matches the hostname-arp.txt file with the hostname-mac-address.txt file.</p> <p>The second is a Core/IDF deployment where there is a layer 3 switch in an MDF and the closets are connected at layer 2. In this case, we have to use an argument in the procurve-macaddr.py script to tell it which hostname-arp.txt file to use for each hostname-mac-address.txt file.</p>"},{"location":"Helper-scripts/#running-the-procurve-arppy-script","title":"Running the procurve-arp.py script","text":"<p>Example of a distributed layer 3 deployment:</p> <p><code>python3 procurve-arp.py -s area1</code></p> <p>The script will create the hostname-Mac2IP.json and will print some information to the screen. The first information is the file being processed and the number of IPs and the IPs sorted. Here is an example:</p> <pre><code>----------------------------------------------------------------------------------------\nReading devices from: /home/mhubbard/04_Tools/Discovery/port-maps/data/test-Core-arp.txt\n----------------------------------------------------------------------------------------\nNumber of IP Addresses: 566\n---------------------------\n10.1.0.252\n10.112.1.3\n</code></pre> <p>The next output is IP and MAC Addresses. Here is an example:</p> <pre><code>Number of IP and MAC Addresses: 566\n-----------------------------------\n10.1.0.252 04d590-0e77ab\n10.112.1.3 883a30-76ce00\n</code></pre> <p>And finally, the IP, MAC and Manufacture. Here is an example:</p> <pre><code>Number of IP, MAC and Manufacture: 566\n--------------------------------------\n10.1.0.252 04d590-0e77ab Fortinet\n10.112.1.3 883a30-76ce00 ArubaaHe\n</code></pre> <p>If you have a need for this information great, if not just ignore it.</p>"},{"location":"Helper-scripts/#running-the-procurve-macaddrpy-script","title":"Running the procurve-macaddr.py script","text":"<p>This script reads the hostname-Mac2IP.json and hostname-mac-address.txt files and creates the port maps. The port maps are saved in the final folder under port-maps.</p> <p><code>python3 procurve-macaddr.py -s area1</code></p>"},{"location":"Helper-scripts/#coreidf-deployment","title":"Core/IDF deployment","text":"<p>In this case only the core switch has the arp records. The argument \"-c coreswitch\" is used to tell the switch to use the core-arp.txt file for all switches.</p> <p><code>python3 procurve-macaddr.py -s area1 -c coreswitch</code></p>"},{"location":"Helper-scripts/#cdp-neighbor-reports","title":"CDP Neighbor Reports","text":"<p>The Procurve switches support the Cisco discovery protocol (cdp) even though it's a Cisco proprietary protocol. By default it's not running. If you want to use cdp you have to enable it.</p> <pre><code>HP-2920-24G-PoEP# config t\nHP-2920-24G-PoEP(config)# cdp run\n</code></pre> <p>Optionally you can enable cdp on only certain ports. For example,</p> <pre><code>HP-2920-24G-PoEP(config)# cdp enable ?\n[ethernet] PORT-LIST  Enter a port number, a list of ports or 'all' for all ports.\n</code></pre> <p>There is an argument that having CDP enabled on all ports is a security risk. You have to decide for yourself if the risk is worth the visibility of running CDP. Personally, my feeing is that if an attacker has unfettered access to your switches the game is already over so I enable it.</p> <p>The exception is for ports that connect to external entities such as an ISP or extranet partner.</p> <p>To view the list of ports that have cdp enabled:</p> <pre><code>sh cdp\n\n Global CDP information\n\n  Enable CDP [Yes] : Yes\n  CDP mode [rxonly] : rxonly\n\n\n  Port   CDP\n  ------ --------\n  1      enabled\n  2      enabled\n  3      enabled\n</code></pre> <p>To view all the cdp options, from configuration mode, you can use</p> <pre><code>cdp ?\n enable                Enable CDP on particular device ports.\n mode                  Set various modes of CDP (Cisco Discovery Protocol) processing.\n run                   Start CDP on the device.\n ```\n\n### The cdp scripts\n\n There are two scripts for CDP neighbors.\n\n- procurve-cdp-ne-report.py - This script creates a text file for the cdp neighbors\n- procurve-cdp-ne-csv.py - This script creates a CSV file for the cdp neighbors\n\nI wrote the script that creates the csv file so that you could use a spreadsheet or the Rainbow csv extension to sort the data.\n\nEach of these scripts uses the same device-inventory file as the procurve-Config-pull.py script so there is no configuration needed. Just use:\n\n- `python3 procurve-cdp-ne-report.py -s sitename`\n- `python3 procurve-cdp-ne-csv.py -s sitename`\n\nThe reports are saved into the \"Interface\\neighbors\" directory.\n\n### The cdp neighbor text report\n\nThe first script creates a nicely formatted text file.\n\nHere is a snippet of the cdp neighbor text report:\n\n```bash\n------------------------------\ndestination_host: 3750x.pu.pri\n   management_ip: 192.168.1.1\n        platform: cisco WS-C3750X-48P\n     remote_port: GigabitEthernet1/1/2\n      local_port: 21\nsoftware_version: Cisco IOS Software, C3750E Software (C3750E-UNIVERSALK9-...\n</code></pre> <p>You can use it as is but since it's text so you can use grep to filter anything you want. For example, to filter on uplink ports on a Cisco switch:</p> <p><code>grep -Eir -b4 \"GigabitEthernet1/1/\" *cdp-report.txt</code></p> <p>Here is a snippet of the output:</p> <pre><code>Procurve-2920-48-cdp-report.txt-824-------------------------------\nProcurve-2920-48-cdp-report.txt-855-destination_host: 64 00 f1 01 6f 80\nProcurve-2920-48-cdp-report.txt-891-   management_ip: 192.168.1.1\nProcurve-2920-48-cdp-report.txt-921-        platform: Cisco IOS Software, C3750E Software (C3750E-UNIVERSALK9-...\nProcurve-2920-48-cdp-report.txt:999:     remote_port: GigabitEthernet1/1/2\nProcurve-2920-48-cdp-report.txt-1038-      local_port: 21\nProcurve-2920-48-cdp-report.txt-1059-software_version: Cisco IOS Software, C3750E Software (C3750E-UNIVERSALK9-...\nProcurve-2920-48-cdp-report.txt-1137-\nProcurve-2920-48-cdp-report.txt-1138-\nProcurve-2920-48-cdp-report.txt-1139-------------------------------\nProcurve-2920-48-cdp-report.txt-1170-destination_host: 3750x.pu.pri\nProcurve-2920-48-cdp-report.txt-1201-   management_ip: 192.168.1.1\nProcurve-2920-48-cdp-report.txt-1231-        platform: cisco WS-C3750X-48P\nProcurve-2920-48-cdp-report.txt:1269:     remote_port: GigabitEthernet1/1/4\nProcurve-2920-48-cdp-report.txt-1308-      local_port: 22\nProcurve-2920-48-cdp-report.txt-1329-software_version: Cisco IOS Software, C3750E Software (C3750E-UNIVERSALK9-...\n</code></pre> <p>Here is a screenshot of the csv report in Libre Office Calc:</p> <p> </p>"},{"location":"Helper-scripts/#lldp-neighbor-report","title":"LLDP neighbor Report","text":"<p>The Procurve switches support the Link Layer discovery protocol (lldp). LLDP is an open standard protocol so it will be found on most non-Cisco devices. If you are using Mac/Linux you can install the LLDP daemon and participate. I recommend doing that because it's very useful to be able to see what you are connected to. Also, if you run <code>show lldp</code> on a switch, you will see your device.</p> <p>Here is my Ubuntu laptop as seen by the 2920:</p> <pre><code>  LocalPort | ChassisId          PortId             PortDescr SysName\n  --------- + ------------------ ------------------ --------- ------------------\n  24        | 54 bf 64 3b 9c 68  28 d0 ea 93 2a 42  wlp61s0   1S1K-G5-5587\n</code></pre> <p>Explanation of output:</p> <ul> <li>24 - The port the lldp neighbor is connected to</li> <li>54 bf 64 3b 9c 68 - The Chassis ID. In this case, it's the mac address of my laptop's ethernet interface</li> <li>28 d0 ea 93 2a 42 - The port ID. This mac address of the wireless interface That is the interface that is connected to the network.</li> <li>wlp61s0 - The name of the wireless interface that is connected to the network.</li> <li>1S1K-G5-5587 - The hostname of my laptop</li> </ul>"},{"location":"Helper-scripts/#installing-lldp-on-ubuntu","title":"Installing LLDP on Ubuntu","text":"<p>This blog is a good starting point for installing LLDP on Ubuntu. There are many public blogs on how to do it and a quick Google search or asking chatGPT will get you started.</p>"},{"location":"Helper-scripts/#installing-lldp-on-macos","title":"Installing LLDP on macOS","text":"<p>I use homebrew to install applications on the Mac and lldp is just <code>brew install lldp</code>.</p>"},{"location":"Helper-scripts/#enabling-lldp-on-the-switch","title":"Enabling LLDP on the switch","text":"<p>By default lldp is  not running. If you want to use lldp you have to enable it using:</p> <pre><code>config t\nlldp run\n</code></pre> <p>Then you can use the following command to see the lldp configuration:</p> <pre><code>show lldp config\n\n LLDP Global Configuration\n\n  LLDP Enabled [Yes] : Yes\n  LLDP Transmit Interval    [30] : 30\n  LLDP Hold time Multiplier  [4] : 4\n  LLDP Reinit Interval       [2] : 2\n  LLDP Notification Interval [5] : 5\n  LLDP Fast Start Count      [5] : 5\n\n\n LLDP Port Configuration\n\n  Port  | AdminStatus NotificationEnabled Med Topology Trap Enabled\n  ----- + ----------- ------------------- -------------------------\n  1     | Tx_Rx       False               False\n  2     | Tx_Rx       False               False\n</code></pre> <p>You can customize LLDP using the following:</p> <pre><code>HP-2920-24G-PoEP(config)# lldp\n admin-status          Set the port operational mode.\n auto-provision        Configure radio port automatic provisioning.\n config                Set the TLV parameters to advertise on the specified ports.\n enable-notification   Enable notification on the specified ports.\n fast-start-count      Set the MED fast-start count in seconds.\n holdtime-multiplier   Set the holdtime multipler.\n refresh-interval      Set refresh interval/transmit interval in seconds.\n run                   Start LLDP on the device.\n top-change-notify     Enable LLDP MED topology change notification.\n</code></pre> <p>As you can see there are a lot of options available. Setting these options is beyond the scope of this article.</p> <p>But it is interesting to note that you can change the basic Type, Length, Value (TLV) parameters that are advertised.</p> <pre><code>HP-2920-24G-PoEP(config)# lldp config\n [ethernet] PORT-LIST  Enter a port number, a list of ports or 'all' for all ports.\nHP-2920-24G-PoEP(config)# lldp config 1\n basicTlvEnable        Specify the basic TLV List to advertise.\n dot1TlvEnable         Specify the 802.1 TLV list to advertise.\n dot3TlvEnable         Specify the 802.3 TLV list to advertise.\n ipAddrEnable          Specify the IP address to enable.\n medPortLocation       Configure the location ID information to advertise.\n medTlvEnable          Specify the MED TLV list to advertise.\n\nHP-2920-24G-PoEP(config)# lldp config 1 basicTlvEnable\n port_descr            Port Description TLV\n system_name           System Name TLV\n system_descr          System Description TLV\n system_cap            System Capability TLV\n management_addr       Management Address TLV\n</code></pre>"},{"location":"Helper-scripts/#running-the-script","title":"Running the script","text":"<p>The script uses the same device-inventory file as the procurve-Config-pull.py script so there is no configuration needed. Just use:</p> <ul> <li><code>python3 procurve-lldp-ne-report.py -s sitename</code></li> </ul> <p>The report is saved into the \"Interface\\neighbors\" directory.</p> <p>Here is a snippet of the report:</p> <pre><code>           neighbor_sysname: 3750x.pu.pri\n  remote_management_address: 10.254.34.17\n      neighbor_chassis_type: mac-address\n        neighbor_chassis_id: 64 00 f1 01 6f 80\n               system_descr: Cisco IOS Software, C3750E Software (C3750E-UNIVERSALK9-M...\n            neighbor_portid: Gi1/0/1\n                 local_port: 1\n               system_descr: Cisco IOS Software, C3750E Software (C3750E-UNIVERSALK9-M...\n                       PVID: 850\n                 port_descr: GigabitEthernet1/0/1\nsystem_capabilities_enabled: bridge, router\n</code></pre> <p>I left the labels just as they are in the <code>show command</code>. If you want to change them it's fairly obvious in the script. For example, to change \"remote_management_address\" to \"remote IP address\" look for this line:</p> <p><code>remote_management_address = f'{\"remote_management_address: \" :&gt;29}{data[counter][\"remote_management_address\"]}'</code></p> <p>and change \"remote_management_address: \" to \"remote IP address: \"</p>"},{"location":"Helper-scripts/#the-system-report","title":"The System Report","text":"<p>The system report will be useful for filling out the Change request form or a transmittal. Again, being a plain text file you will be able to use grep to filter. For example:</p> <p><code>grep -Eir -b4 \"serial number\" *system-report.txt</code></p> <p>To pull a list of serial numbers from the system reports.</p> <p>Here is a snippet of the system report:</p> <pre><code>        Hostname: HP-2920-24G-PoEP\n   snmp location: Home Lab\n    snmp contact: Michael Hubbard\n MAC address age: 300\n        timezone: -480\n   daylight_rule: Continental-US-and-Canada\nsoftware_version: WB.16.10.0023\n     rom_version: WB.16.03\n     mac address: 98f2b3-fe8880\n   serial number: SG78FLXH0B\n   system_uptime: 3 hours\n cpu_utilization: 47\n        mem_free: 40,344,656\n</code></pre>"},{"location":"Helper-scripts/#the-interface-scripts","title":"The Interface scripts","text":"<p>There are two scripts for interfaces:</p> <ul> <li>procurve-10Mb.py - Creates a list of interfaces that are running at 10Mbps full or half duplex.</li> <li>procurve-interface-in-use.py - Creates a list of interfaces that have a \"total_byte\" count not equal to 0.</li> </ul> <p>I wrote the script that creates the 10Mbps list because smartrate and mGig ports don't support 10Mbps rates. From personal experience I can tell you that it's better to find out in the discovery phase than the deployment phase.</p> <p>Devices running at 10Mbps full or half are usually door access controllers or Building Automation controllers. You will not have any success getting them replaced before the deployment phase begins. To verify you can use the port maps and look up the manufacturer.</p> <p>The interface report for \"in use\" was requested so that decisions about consolidating interfaces could be made. It has the \"uptime\" of the switch as the first line in the file so that there is some context about the zero bytes. For example, if the switch has an uptime of a few days then the ports not in use could be employees on vacation for devices that are used infrequently.</p> <p>Each of these scripts uses the same device-inventory file as the procurve-Config-pull.py script so there is no configuration needed. Just use:</p> <ul> <li><code>python3 procurve-10Mb.py -s sitename</code></li> <li><code>python3 procurve-interface-in-use.py -s sitename</code></li> </ul> <p>The reports are saved into the \"CR-data\" directory.</p>"},{"location":"Helper-scripts/#the-10mbps-interfaces-report","title":"The 10Mbps interfaces report","text":"<p>This script creates a simple text file with the filename format of \"hostname-10Mb-Ports.txt\". For example:</p> <p><code>Procurve-2930-48-10Mb-Ports.txt</code></p> <p>Here is a snippet of the cdp neighbor text report:</p> <pre><code>Interface 2 - 10FDx\nInterface 3 - 10HDx\n</code></pre>"},{"location":"Helper-scripts/#the-ports-in-use-report","title":"The ports in use report","text":"<p>This script creates a simple text file with the filename format of hostname-Port-data.txt. For example:</p> <p><code>Procurve-2920-48-Port-data.txt</code></p> <p>Here is a snippet of the cdp neighbor text report:</p> <pre><code>System Uptime: 3 hours\n\nNumber of Interfaces with traffic: 5\nInterface 1 - total_bytes 1,510,198\nInterface 2 - total_bytes 0\nInterface 3 - total_bytes 0\nInterface 4 - total_bytes 0\nInterface 5 - total_bytes 0\nInterface 6 - total_bytes 0\nInterface 7 - total_bytes 1,054,112\n</code></pre>"},{"location":"Helper-scripts/#convert-mac-addresses","title":"Convert MAC addresses","text":"<p>This simple script takes 1 argument, a MAC address in any of the following formats and returns it in all of the formats.</p> <ul> <li>64:e8:81:43:cc:4e</li> <li>64e881-43cc4e</li> <li>64e8.8143.cc4e</li> <li>64-e8-81-43-cc-4e</li> <li>64e88143cc4e</li> </ul> <pre><code>python3 convert-mac.py --mac 64:e8:81:43:cc:4e\n64:e8:81:43:cc:4e\n64e881-43cc4e\n64e8.8143.cc4e\n64-e8-81-43-cc-4e\n64e88143cc4e\n</code></pre>"},{"location":"SECURITY/","title":"Security Policy","text":"<p>The Network Discovery project community has adopted this security disclosures and response policy to ensure we responsibly handle critical issues.</p>"},{"location":"SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":""},{"location":"SECURITY/#when-should-you-report-an-issue","title":"When should you report an issue?","text":"<ul> <li>You think you discovered a potential security vulnerability in one of the scripts.</li> <li>You are unsure how a vulnerability affects the project.</li> <li>You think you discovered a vulnerability in another project that a script depends on. For projects with their own vulnerability reporting and disclosure process, please report it directly there.</li> </ul>"},{"location":"SECURITY/#when-you-should-not","title":"When you should not?","text":"<ul> <li>You need help tuning the components for security</li> <li>You need help applying security-related updates.</li> <li>Your issue is not security-related.</li> </ul>"},{"location":"SECURITY/#please-use-the-below-process-to-report-a-vulnerability-to-the-project","title":"Please use the below process to report a vulnerability to the project","text":"<p>Email the Network Discovery Security Team at <code>michael.hubbard999 -@- gmail.com</code></p> <p>The email should contain:</p> <ul> <li>description of the problem</li> <li>precise and detailed steps (include screenshots) that created the problem</li> <li>the affected version(s)</li> <li>any possible mitigations, if known</li> </ul>"},{"location":"Using_PowerShell/","title":"PowerShell Win/Mac/Linux","text":"<p>Here are the steps I took to get Windows terminal installed, the latest version of PowerShell configured with history and some other Linux like features. Also the <code>procs</code> tool for viewing processes in a Unix like format.</p>"},{"location":"Using_PowerShell/#getting-started","title":"Getting Started","text":"<p>The first step is installing the Windows Terminal. While not strictly required, you could use the cmd.exe shell, I find the Windows Terminal a much better solution. It allows:</p> <p>Multiple applications in one application</p> <ul> <li>PowerShell</li> <li>WSL</li> <li>Git Bash</li> <li>CMD.exe</li> <li>Azure Cloud Shell</li> </ul> <p>Here is a screenshot of my Windows Terminal menu:</p> <p></p> <p>You can see that I have organized it so that Ubuntu 24.04 is at the top, then PowerShell 7, then Git Bash, then Command Prompt. The PowerShell without a number is the builtin version 5.1. Since I use WSL and PowerShell 7.5 the most, this makes sense for me. After we install PowerShell 7.5, I'll show you how to modify the order.</p> <p>This article: Windows Terminal vs. Command Prompt vs. PowerShell: Which Should You Use? covers the differences between cmd.exe, powershell, wsl, and Windows Terminal. To sum up:</p> <p>Windows Terminal is the newest member of the group. Rather than being a shell itself, it serves as a modern interface for hosting multiple shells. You can run CMD, PowerShell, and even Linux distributions through Windows Subsystem for Linux (WSL) all within a single, customizable window. With features like tabs, Unicode support, and GPU-accelerated rendering, it makes multitasking smoother and more efficient.</p>"},{"location":"Using_PowerShell/#install-windows-terminal","title":"Install Windows Terminal","text":"<p>Installing the Windows Terminal is simple.</p> <ul> <li>Click the start menu</li> <li>Type <code>microsoft store</code> and press <code>enter</code></li> <li>Search for <code>Windows Terminal</code></li> <li>Click on the <code>Free</code> button</li> <li>click on <code>Get</code></li> </ul> <p></p>"},{"location":"Using_PowerShell/#install-the-latest-version-of-powershell-core","title":"Install the latest version of PowerShell core","text":"<p>Windows 11 ships with PowerShell 5.1 installed. I don't understand all the reasons behind it, but PowerShell 7.5 is the latest version and it installs BESIDE PowerShell 5.1. That is really confusing and both versions store their <code>$PROFILE</code> in separate locations!</p> <p>Open cmd.exe and paste the following code:</p> <p><code>winget install --id Microsoft.PowerShell --source winget</code></p> <p>This will install the latest version of PowerShell 7. If PowerShell 7 is already installed, it will fail and tell you to run upgrade instead.</p> <p>In that case, run the following code to verify that PowerShell is up to date:</p> <p><code>winget upgrade --id Microsoft.PowerShell --source winget</code></p>"},{"location":"Using_PowerShell/#check-the-powershell-version","title":"Check the Powershell version","text":"<p>Search <code>terminal</code> in Windows search bar and open it. Click the  in the top menu and select PowerShell. Once you are in the PowerShell terminal you can check the version with <code>$PSVersionTable</code>. Here is what the output looked like on my fresh install:</p> <pre><code>(Discovery) PS C:\\Users\\mhubbard.PU\\Documents\\04_tools\\Discovery&gt; $PSVersionTable\n\nName                           Value\n----                           -----\nPSVersion                      7.5.1\nPSEdition                      Core\nGitCommitId                    7.5.1\nOS                             Microsoft Windows 10.0.26100\nPlatform                       Win32NT\nPSCompatibleVersions           {1.0, 2.0, 3.0, 4.0\u2026}\nPSRemotingProtocolVersion      2.3\nSerializationVersion           1.1.0.1\nWSManStackVersion              3.0\n</code></pre>"},{"location":"Using_PowerShell/#add-a-persistent-history-and-command-search","title":"Add a persistent history and command search","text":"<p>This is a must have feature and gives PowerShell some zsh like capabilities.</p>"},{"location":"Using_PowerShell/#create-the-powershell-7-profile","title":"Create the PowerShell 7 profile","text":"<p>For some reason installing PowerShell 7 with winget didn't create the profile. We will use this PowerShell code to do it. Click on the <code>copy</code> icon on the right to copy the code and paste it into the PowerShell terminal:</p> <pre><code>if (!(Test-Path -Path $PROFILE)) {\n    New-Item -ItemType File -Path $PROFILE -Force\n}\n</code></pre> <p>You can see the path to the file by running:</p> <pre><code> echo $profile\nC:\\Users\\mhubbard.PU\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1\n</code></pre> <p>Tip</p> <p>You can view all profiles that PowerShell 7 sees using</p> <pre><code> $PROFILE | Select-Object *\n  AllUsersAllHosts       : C:\\Program Files\\PowerShell\\7\\profile.ps1\n  AllUsersCurrentHost    : C:\\Program Files\\PowerShell\\7\\Microsoft.PowerShell_profile.ps1\n  CurrentUserAllHosts    : C:\\Users\\mhubbard.PU\\OneDrive\\Documents\\PowerShell\\profile.ps1\n  CurrentUserCurrentHost : C:\\Users\\mhubbard.PU\\OneDrive\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1\n  Length                 : 83\n</code></pre> <p>We want to modify the profile. Open it using <code>notepad $PROFILE</code>. Then paste in the following:</p> <pre><code>Import-Module PSReadLine\nSet-PSReadLineOption -PredictionSource History\nSet-PSReadLineOption -HistorySearchCursorMovesToEnd # Optional: moves cursor to end of matched command\nSet-PSReadLineKeyHandler -Key UpArrow -Function HistorySearchBackward\nSet-PSReadLineKeyHandler -Key DownArrow -Function HistorySearchForward\n\nfunction Invoke-CsvLensWithArgs {\n    csvlens.exe --color-columns --no-headers @args\n}\n\n# --- Custom aliases for Discovery tool ---\nSet-Alias -Name cl -Value Invoke-CsvLensWithArgs\n# --- End custom aliases for Discovery tool ---\n\n Invoke-Expression (&amp; { (zoxide init powershell | Out-String) })\n\n# Load persistent PSReadLine history into session memory\nif (Test-Path (Get-PSReadlineOption).HistorySavePath) {\n    Get-Content (Get-PSReadlineOption).HistorySavePath | ForEach-Object { Add-History $_ }\n}\n</code></pre> <p>The first line imports the <code>PSReadLine</code> module. This tells PowerShell to read the history file.</p> <p>The next 4 lines setup a history search capability. That is so useful, if you have typed a command previously, you just type the first few letters and tap the up arrow. It will cycle through all commands that match.</p> <p>The <code>function Invoke-CsvLensWithArgs</code> creates an alias for csvlens that automatically adds the <code>--color-columns</code> and <code>--no-headers</code> needed to view the device inventory files.</p> <p>Note</p> <p>If you installed PowerShell On Mac/Linux, use <code>csvlens --color-columns --no-headers @args</code> instead of <code>csvlens.exe --color-columns --no-headers @args</code></p> <p>The line <code>Set-Alias -Name cl -Value Invoke-CsvLensWithArgs</code>, builds the alias. In this case, typing <code>cl</code> invokes the alias.</p> <p>Finally, the line <code>Invoke-Expression (&amp; { (zoxide init powershell | Out-String) })</code> adds <code>zoxide</code> to the profile. Zoxide is a tool that builds a database of the directories you go to then allows you to <code>jump</code> to them with just a few keystrokes.</p> <p>For example, once you have installed the scripts to the <code>Discovery</code> folder and navigated to them at least once you can just type <code>z dis</code> and it will jump you to the directory.</p>"},{"location":"Using_PowerShell/#load-the-history-file","title":"Load the history file","text":"<p>PowerShell's persistent history is primarily managed by the PSReadLine module. This module tracks the commands you enter and saves them to a history file.</p> <p>You can enter <code>(Get-PSReadlineOption).HistorySavePath</code> to find the location of the history file.</p> <p>Windows</p> <p>For me, the file is located at <code>C:\\Users\\mhubbard.PU\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadLine\\ConsoleHost_history.txt</code>.</p> <p>Linux</p> <p>For me, the file is located at <code>/home/mhubbard/.local/share/powershell/PSReadLine/ConsoleHost_history.txt</code>.</p> <p>When I closed PowerShell I lost the history. I did a bunch of <code>Gemini</code> searching and found you have to add some code to the <code>$profile</code> to make PowerShell display history from the previous session.</p> <p>You can display history using: <code>cat (Get-PSReadlineOption).HistorySavePath</code></p> <p>and search history using: <code>cat (Get-PSReadlineOption).HistorySavePath | Select-String &lt;Something&gt;</code></p> <p>If you have been using a loaner laptop, you can delete the entire history file using: <code>Remove-Item (Get-PSReadlineOption).HistorySavePath</code></p> <p>Change how PowerShell command history is saved:</p> <pre><code>Set-PSReadlineOption -HistorySaveStyle SaveIncrementally # default\nSet-PSReadlineOption -HistorySaveStyle SaveAtExit\nSet-PSReadlineOption -HistorySaveStyle SaveNothing\n</code></pre> <p>To make history persist across sessions open the $profile and paste this into the bottom of the file.</p> <pre><code># Load previous persistent history into current session's Get-History list\nfunction full-history {\n    $historyPath = (Get-PSReadlineOption).HistorySavePath\n    if (Test-Path $historyPath) {\n        $lines = Get-Content $historyPath | Where-Object { $_.Trim() -ne \"\" }\n        $index = 1\n        $lines | ForEach-Object {\n            [PSCustomObject]@{\n                Line    = $index\n                Command = $_\n            }\n            $index++\n        } | Format-Table -AutoSize\n    }\n    else {\n        Write-Host \"No history file found.\"\n    }\n}\n\n# Show numbered history list like Bash\nfunction Show-HistoryList {\n    $historyPath = (Get-PSReadlineOption).HistorySavePath\n    if (-not (Test-Path $historyPath)) {\n        Write-Host \"No history file found\"\n        return\n    }\n\n    $lines = Get-Content $historyPath | Where-Object { $_.Trim() -ne \"\" }\n\n    $i = 1\n    foreach ($line in $lines) {\n        \"{0,4}: {1}\" -f $i, $line\n        $i++\n    }\n}\nSet-Alias h Show-HistoryList  # Use `h` to show numbered history\n\n# Run a command by its history line number\nfunction Run-HistoryCommand {\n    param (\n        [Parameter(Mandatory)]\n        [int]$Number\n    )\n\n    $historyPath = (Get-PSReadlineOption).HistorySavePath\n    if (-not (Test-Path $historyPath)) {\n        Write-Host \"History file not found.\"\n        return\n    }\n\n    $lines = Get-Content $historyPath | Where-Object { $_.Trim() -ne \"\" }\n\n    if ($Number -lt 1 -or $Number -gt $lines.Count) {\n        Write-Host \"Invalid history number: $Number\"\n        return\n    }\n\n    $command = $lines[$Number - 1]\n\n    Write-Host \"`n&gt; $command`n\"\n    Invoke-Expression $command\n}\nSet-Alias rh Run-HistoryCommand  # Use `rh &lt;n&gt;` to run previous command\n\n\n# \u2705 Load previous session commands into PSReadLine session history\n# ~/.config/powershell/Microsoft.PowerShell_profile.ps1 or $PROFILE\n\n$ExecutionContext.InvokeCommand.PostCommandLookupAction = {\n    # Only run this once\n    if (-not $script:HistoryLoaded) {\n        $script:HistoryLoaded = $true\n\n        $historyPath = (Get-PSReadlineOption).HistorySavePath\n        if (Test-Path $historyPath) {\n            Get-Content $historyPath |\n                Where-Object { -not [string]::IsNullOrWhiteSpace($_) } |\n                ForEach-Object {\n                    [Microsoft.PowerShell.PSConsoleReadLine]::AddToHistory($_)\n                }\n        }\n    }\n}\n</code></pre> <p>Close PowerShell and reopen it. type <code>h</code> to see history from all sessions. The  and   keys will navigate through the history.</p> <p>There is also an alias <code>rh history number</code> that will run the command given by the history number.</p> <p>The code also adds line numbers like in the Mac/Linux history.</p> <p>example</p> <pre><code>h\n   1: exit\n   2: echo $profile\n   3: nano $PROFILE\n  4: cl\n</code></pre> <p>Now rerun the <code>echo $profile</code> alias</p> <pre><code>rh 2\n&gt; echo $profile\n/home/mhubbard/.config/powershell/Microsoft.PowerShell_profile.ps1\n</code></pre> <p>I ran this on Ubuntu, but it works on Windows and Mac the same way!</p> <p></p>"},{"location":"Using_PowerShell/#install-zoxide","title":"Install Zoxide","text":"<p>Zoxide works on Mac/Linux/Windows! The project is hosted on GitHub at zoxide. To install on Windows:</p> <pre><code>winget install ajeetdsouza.zoxide\nzoxide init powershell\n</code></pre> <p>The winget command does the install, the zoxide init powershell adds the line we saw above to the PowerShell profile. I cannot recommend <code>zoxide</code> enough.</p>"},{"location":"Using_PowerShell/#install-procs","title":"Install procs","text":"<p>Procs is a modern replacement for venerable Linux/Unix <code>ps</code> command written in <code>rust</code>. It's cross platform and available for Mac/Linux and Windows.</p> <p>From a <code>cmd.exe</code> shell, run:</p> <p><code>winget install procs</code></p> <p>You will need to close the terminal and reopen to use <code>procs</code></p> <p>Features</p> <ul> <li>Colored and human-readable output<ul> <li>Automatic theme detection based on terminal background</li> </ul> </li> <li>Multi-column keyword search</li> <li>Some additional information which are not supported by ps<ul> <li>TCP/UDP port</li> <li>Read/Write throughput</li> <li>Docker container name</li> <li>More memory information</li> </ul> </li> <li>Pager support</li> <li>Watch mode (like top)</li> <li>Tree view</li> </ul> <p>While not required, it's a nice tool and if you work on more than one OS it is nice to have common tools. Here is a screenshot of <code>procs</code> with no arguments:</p> <p></p> <p>Search by non-numeric keyword</p> <p>If you include a nonnumeric keyword, only processes matching the keyword will be shown. For example, to find processes starting with <code>wind</code>:</p> <p><code>procs wind</code></p> <p></p> <p>Display dependencies in a tree view</p> <p><code>procs --tree</code></p> <p></p> <p>There are many more options for sorting, adding columns, viewing Docker containers, etc. Please visit the Procs GitHub repo for full details.</p>"},{"location":"Using_PowerShell/#change-the-order-in-terminal","title":"Change the order in Terminal","text":"<p>This is optional but if you use Windows Terminal often it's worth customizing the order that your shells are displayed in.</p> <ul> <li>Open Windows Terminal</li> <li>Click the  in the top menu</li> <li>Click <code>settings</code></li> <li>Click <code>Open JSON File</code> at the very bottom, left of the terminal.</li> </ul> <p></p> <p>Note</p> <p>On my Windows laptop, Windows Terminal always opens with the bottom of the terminal below the bottom of the screen. I couldn't see the Open JSON file option until dragging the window up. Holding <code>shift</code> while clicking the <code>X</code> to close hasn't resolved the issue.</p> <p>Scroll down until you see</p> <pre><code>\"list\":\n        [\n            {\n                \"commandline\": \"%SystemRoot%\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\n                \"guid\": \"{61c54bbd-c2c6-5271-96e7-009a87ff44bf}\",\n                \"hidden\": true,\n                \"name\": \"Windows PowerShell 7\"\n            },\n</code></pre> <p>Your exact JSON will be different than mine so you will see something different. The important thing is finding <code>\":list\":</code> in the JSON file. Copy everything from <code>\"list\":</code> to the last <code>}</code> before the <code>]</code> symbol and save it to notepad++ or your favorite editor. Save a copy as a backup in case you make a mistake editing <code>settings.json</code>.</p>"},{"location":"Using_PowerShell/#move-the-shells","title":"Move the shells","text":"<p>Now you can cut each shell and move it to the order you want. I renamed <code>Windows PowerShell</code> to <code>Windows PowerShell 7</code> so that it's obvious which version to select.  When you are satisfied, save and close the <code>settings.json</code> file.</p> <p>Notice the <code>\"hidden\": true,</code> and <code>\"hidden\": false,</code> lines. I don't know why some shells have two entries with one hidden and one not.</p> <p>Here is what my final JSON looks like:</p> <pre><code>        \"list\":\n        [\n            {\n                \"commandline\": \"%SystemRoot%\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\",\n                \"guid\": \"{61c54bbd-c2c6-5271-96e7-009a87ff44bf}\",\n                \"hidden\": true,\n                \"name\": \"Windows PowerShell 7\"\n            },\n            {\n                \"guid\": \"{d8e96812-b789-5068-a5ae-10b2fb53e95f}\",\n                \"hidden\": false,\n                \"name\": \"Ubuntu 24.04.1 LTS\",\n                \"source\": \"CanonicalGroupLimited.Ubuntu24.04LTS_79rhkp1fndgsc\"\n            },\n            {\n                \"guid\": \"{5fb123f1-af88-5b5c-8953-d14a8def1978}\",\n                \"hidden\": false,\n                \"name\": \"PowerShell 7\",\n                \"source\": \"Windows.Terminal.PowershellCore\"\n            },\n            {\n                \"guid\": \"{2ece5bfe-50ed-5f3a-ab87-5cd4baafed2b}\",\n                \"hidden\": false,\n                \"name\": \"Git Bash\",\n                \"source\": \"Git\"\n            },\n            {\n                \"commandline\": \"%SystemRoot%\\\\System32\\\\cmd.exe\",\n                \"guid\": \"{0caa0dad-35be-5f56-a8ff-afceeeaa6101}\",\n                \"hidden\": false,\n                \"name\": \"Command Prompt\"\n            },\n            {\n                \"guid\": \"{b453ae62-4e3d-5e58-b989-0a998ec441b8}\",\n                \"hidden\": false,\n                \"name\": \"Azure Cloud Shell\",\n                \"source\": \"Windows.Terminal.Azure\"\n            },\n            {\n                \"guid\": \"{574e775e-4f2a-5b96-ac1e-a2962a402336}\",\n                \"hidden\": false,\n                \"name\": \"PowerShell\",\n                \"source\": \"Windows.Terminal.PowershellCore\"\n            },\n            {\n                \"guid\": \"{963ff2f7-6aed-5ce3-9d91-90d99571f53a}\",\n                \"hidden\": true,\n                \"name\": \"Ubuntu-24.04\",\n                \"source\": \"Windows.Terminal.Wsl\"\n            },\n            {\n                \"guid\": \"{43a35048-5e42-5c40-8a75-f5b7bfec7d65}\",\n                \"hidden\": false,\n                \"name\": \"Developer Command Prompt for VS 2019\",\n                \"source\": \"Windows.Terminal.VisualStudio\"\n            },\n            {\n                \"guid\": \"{b7ba4424-3cd0-5300-927c-57d95790a11f}\",\n                \"hidden\": false,\n                \"name\": \"Developer PowerShell for VS 2019\",\n                \"source\": \"Windows.Terminal.VisualStudio\"\n            }\n        ]\n</code></pre>"},{"location":"intro/","title":"The Network Discovery Project","text":"<p>This project was created to make the discovery process for a network refresh easy, consistent and comprehensive. The discovery data can be used to create a change request, and cut over plan for the customer. The data is also valuable when troubleshooting any issues after a switch is replaced.</p> <p>The project currently supports the following devices:</p> <ul> <li>HPE Procurve</li> <li>Cisco IOS</li> <li>Cisco XE</li> <li>Cisco Nexus</li> <li>Aruba CX</li> </ul> <p>A plain text file is used to store the <code>show commands</code> that are sent to the switches. An example file for an HPE Procurve switch can be found here. You are free to customize the file by adding or removing show commands as needed for your discovery.  The script saves the data to various directories for easy access.</p>"},{"location":"intro/#who-is-this-project-for","title":"Who is this project for","text":"<p>Anyone that needs to pull data from HPE Procurve, Cisco IOS or Aruba CX switches. You do not need to write any python code. Text files are used to collect the information used by the script. You do not need to be a Python programmer to use this project.</p>"},{"location":"intro/#the-process","title":"The Process","text":"<p>There are two types of scripts in the project:</p> <ul> <li>Discovery - These are scripts that use netmiko to connect to a switch and pull down data. No configuration commands are sent so the script is safe to use in production.</li> <li>Helper - These are scripts that take the data that was collected with the discovery script and convert usable reports. They are run offline and do not make any changes to the switches.</li> </ul> <p>The python discovery script config-pull.py uses the industry standard  netmiko Python library and the Network to Code textFSM libraries to connect to a switch, run show commands and create JSON files. These two libraries hide the complexity of connecting to and interacting with network devices.</p>"},{"location":"intro/#show-commands","title":"show commands","text":"<p>The show commands are saved to a file named {vendor-id}-config-file.txt, where vendor-id is:</p> <ul> <li>hp_procurve</li> <li>cisco_ios</li> <li>cisco_xe</li> <li>cisco_nx</li> <li>aruba_cx</li> </ul> <p>.  This file can be edited to send any show commands you need.</p> <p>The format is:</p> <p><code>show 'command'</code> with each command on a separate line. Here is a snippet of the file:</p> <pre><code>show system\nshow config status\nshow oobm\nshow oobm ip\n</code></pre> <p>The show commands are saved to the CR-data directory using the format [hostname]-CR-data.txt. For example, if the hostname is \"Procurve-2920-24\" the filename is Procurve-2920-24-CR-data.txt.</p> <p>On the Procurve switches you can customize the output of show vlans. This HPE Techpub article shows how to do it:</p> <p>Customizing the show VLANs output</p> <p>The procurve-config-file.txt uses the following customizations:</p> <pre><code>show vlan custom id name:15 ipaddr ipmask ipconfig state voice jumbo\n\nStatus and Counters - VLAN Information - Custom view\n\n VLANID VLAN name       IP Addr         IP Mask         IPConfig   State Voice Jumbo\n ------ --------------- --------------- --------------- ---------- ----- ----- -----\n 1      DEFAULT_VLAN                                    DHCP/Bootp Up    No    No\n 10     User            192.168.10.52   255.255.255.0   Manual     Up    No    No\n 20     Voice           10.164.24.200   255.255.255.0   Manual     Up    Yes   No\n 60     IOT0            10.14.66.17     255.255.255.248 Manual     Up    No    No\n 61     IOT1            10.14.65.17     255.255.255.248 Manual     Up    No    No\n 62     IOT2            10.14.64.17     255.255.255.248 Manual     Up    No    No\n 63     IOT3            10.14.63.17     255.255.255.248 Manual     Up    No    No\n 100    test            10.10.100.1     255.255.255.0   Manual     Down  No    No\n 850    OSPF-Peering    10.254.34.18    255.255.255.252 Manual     Up    No    No\n</code></pre> <p>I like the output of this command. You can see vlan id, vlan name, IP Address, IP Mask, Config method, state, voice and jumbo all in one table. This would make a nice alias on the switch.</p> <p><code>alias \"vlan\" \"show vlan custom id name:15 ipaddr ipmask ipconfig state voice jumbo\"</code></p>"},{"location":"intro/#what-are-the-json-files-used-for","title":"What are the JSON files used for","text":"<p>Once the data has been collected, there are helper scripts that use the JSON structured data to create:</p> <ul> <li>CDP neighbor tables</li> <li>LLDP neighbor tables</li> <li>OSPF neighbor tables</li> </ul>"},{"location":"intro/#port-maps","title":"Port Maps","text":"<p>There is also a helper script that reads the arp table of the layer 3 switch and creates a dictionary of mac address to IP address. Then reads the <code>show mac address-table interface</code> data and creates a port map. Here is a sample of what it looks like:</p> <pre><code>Number of Entries: 249\n\nDevice Name: JC-IDF-1\nVlan   IP Address       MAC Address                  Interface             Vendor\n--------------------------------------------------------------------------------\n 100   10.100.126.35    1418.7736.5c5d    dynamic    TenGigabitEthernet1/1 Dell\n--------------------------------------------------------------------------------\n 100   10.100.126.57    14b3.1f0b.61da    dynamic    TenGigabitEthernet1/1 Dell\n--------------------------------------------------------------------------------\n 100   10.100.126.237   38ed.18ec.ccc1    dynamic    TenGigabitEthernet1/1 Cisco\n--------------------------------------------------------------------------------\n 100   10.100.126.136   4487.fc94.9d02    dynamic    TenGigabitEthernet1/1 Elitegro\n</code></pre> <p>The port maps help with planning before a cutover and troubleshooting after a cutover.</p>"},{"location":"intro/#show-running-config","title":"show running-config","text":"<p>A <code>show running-configuration</code> is saved to the \"Running\" directory for each switch. The Procurve firmware allows you to include the \"structured\" keyword after the \"show running-configuration\" command. This groups the output in an easier to read format. For Procurve switches, a show run structured file is created in the \"Running\" directory.</p>"},{"location":"intro/#standard-commands","title":"\"Standard\" Commands?","text":"<p>This script started out to pull configs from Cisco 3750x switches. I was on a long term contract at a customer with about 500 Cisco 3750x switches and was moving to Aruba 6300CX.</p> <p>The script was a life saver pulling all the Change Request data automatically. I then used a great library called <code>cisco_config_parse</code> to read the Cisco running-configuration and convert it to Aruba CX format.</p> <p>When that contract ended I needed to do a refresh at at customer that had HPE Procurve switches. I thought \"how hard could it be to add Procurve?\" Well, it turned out to be an adventure. And then I wanted to pull some Cisco SG small business switch configs, then some Cisco XE. Wow, every vendor has a different way of naming commands. Here is a table that I started so that I could expand the script to cover almost any customer. You can see the problem of adding a new vendor to the mix. And any new vendor has to be supported by Netmiko and Google TextFSM. It's really a nightmare.</p> <p>Then to create a port-map of IP, Vlan, Manufacturer I have to pull the mac-address table and parse it. But that is another challenge because:</p> <ul> <li>hp_procurve - aabbcc-ddeeff</li> <li>cisco ios - aabb.ccdd.eeff</li> <li>aruba_cx - aacc:dd:ee:ff</li> <li>Windows aa-bb-cc-dd-ee-ff</li> </ul> <p>I finally wrote a python script to convert mac addresses from any format to all formats. It's named <code>convert-mac.py</code> and it gets installed when you clone the Discovery repo.</p> <p>Currently I only have Procurve, cisco_ios and cisco_xe fully implemented.</p> Task Cisco IOS Cisco NX-OS Cisco SG/SGX (Small Biz) HP ProCurve Juniper Brocade Dell N1500 Aruba CX Show MAC address <code>show mac address-table</code> / <code>show mac-address</code> <code>show mac address-table</code> <code>show mac-address-table</code> <code>show mac-address</code> <code>show ethernet-switching table</code> <code>show mac-address</code> <code>show mac address-table</code> <code>show mac-address-table</code> Show uptime <code>show version</code> (parse output) <code>show system uptime</code> <code>show system</code> or GUI only <code>show system information</code> <code>show system uptime</code> <code>show system uptime</code> <code>show system</code> <code>show system</code> Show model/serial <code>show inventory</code> / <code>show version</code> <code>show version</code> or <code>show sprom</code> <code>show system</code> <code>show system information</code> <code>show chassis hardware</code> <code>show chassis</code> <code>show system</code> or <code>show version</code> <code>show system</code> Show LLDP neighbors <code>show lldp neighbors detail</code> <code>show lldp neighbors</code> Not supported or limited via GUI <code>show lldp info remote detail</code> <code>show lldp neighbors detail</code> <code>show lldp neighbors</code> <code>show lldp neighbors</code> <code>show lldp neighbors detail</code>"},{"location":"intro/#questions-for-discovery-and-deployment","title":"Questions for Discovery and Deployment","text":"<p>The script will pull any information that you put into the <code>&lt;vendor-id&gt;-config-file.txt</code> file but it can't answer all the questions! Here are some questions I ask during the kickoff meeting with the customer. Some of these questions are open ended and are meant to get the customer engaged in a conversation about the refresh.</p> <p>This is not a exhaustive list, feel free to add to it.</p> <ul> <li>What are the labeling requirements</li> <li>Location</li> <li>What information</li> <li>size</li> <li>material</li> <li>What are the asset Tag requirements?</li> <li>Is an escort required when we are on site?</li> <li>How is access (Keys, codes, alarm codes, etc) granted?</li> <li>If after hours cut overs are required, who is the after hours contact?</li> <li>Will VPN be provided?</li> <li>When on site:</li> <li>Are we allowed to connect our laptops to the network?</li> <li>If not, will a jumpbox be provided?</li> <li>If using a jumpbox can we install tools like python or nmap?</li> <li>Can we use tools like nmap and Wireshark to discover devices?</li> <li>Here are some nmap scripts that I wrote for discovery.</li> <li>Is a change request document required?</li> <li>If so, how many days before the cut over?</li> <li>Who creates the document?</li> <li>Is there a template for the change request document?</li> <li>Who will do the post cut over testing?</li> <li>How long after the cut over until a sign off is completed?</li> <li>If a monitoring tool such as Solarwinds Orion in use:</li> <li>Who disables alerts for the devices being cut over?</li> <li>Will we have access to monitor progress during the cut over?</li> <li>Is a syslog server available that we can access?</li> <li>Firmware</li> <li>What firmware version should be installed?</li> <li>If the project spans months, will switches be put on the current firmware before being deployed?</li> <li>Who will upgrade the switches that have already been deployed?</li> <li>Does the network team have access to M&amp;O devices such as Environmental monitoring (BACnet), surveillance cameras, door access controls?</li> <li>Is DHCP used for non-server hosts i.e. cameras, door access panels, etc?</li> <li>If ClearPass will be used, DHCP allows devices to be profiled.</li> <li>Do you have a standard for host names?</li> <li>A refresh is a good time to make a host name changes if needed.</li> <li>Do you have a management vlan?</li> <li>If so, what are the management vlan IP addresses?</li> <li>default gateway or gateway of last resort IP address?</li> <li>Authentication Server IP address</li> <li>Authentication Server credentials</li> <li>NTP Server</li> <li>IP address</li> <li>Authentication credentials</li> <li>Username/password for base configuration installation</li> <li>Enable password for base configuration</li> <li>Power cord connector requirements</li> <li>NEMA 5-15 (Standard 120v plug)</li> <li>NEMA L5-20 (120v twistlok plug)</li> <li>NEMA L6-20 (240v twistlok plug)</li> <li>IEC C14 (PDU Style plug)</li> <li>Routing protocols</li> <li>Authentication type</li> <li>IPv4</li> <li>IPv6</li> <li>number of areas</li> <li>Rate Limits on edge ports</li> <li>rate-limit bcast</li> <li>rate-limit mcast</li> <li>rate-limit unknown-unicast in</li> <li>Security</li> <li>DHCP Snooping?</li> <li>Dynamic ARP Inspection</li> <li>Authorized Managers</li> <li>no tftp-server (only scp for copying files)</li> <li>snmp requirements</li> <li>Version</li> <li>community names</li> <li>location</li> <li>Required traps</li> <li>What are the spanning-tree requirements?</li> <li>Priority</li> <li>root-guard</li> <li>tcn-guard</li> <li>loop-guard</li> <li>mode</li> <li>admin-edge-port</li> <li>bpdu-protection</li> <li>spanning-tree bpdu-protection-timeout 90</li> <li>ssh - Old ciphers should be removed</li> <li>Host Key type?</li> <li>Ciphers?</li> <li>MACs?</li> <li>key length?</li> <li>Do you use ssh keys instead of passwords?</li> </ul>"},{"location":"intro/#license","title":"License","text":"<p>This project is licensed under the Unlicense - see the LICENSE file for details.</p> <p>https://unlicense.org/</p>"},{"location":"intro/#sbom-a-software-bill-of-materials","title":"SBOM - a Software Bill of Materials","text":"<p>Github has a feature for creating an SPDX compatible SBOM file. From the repository page click: Insights, Dependency Graph, Export SBOM.</p> <p>This project includes a file named sbom.json.</p> <p>You can use tools from the SPDX project to validate and work with the sbom.json file. They have a python script that allows you to output a Graphviz format file. Here is the command I used to create sbom.dot.</p> <p>`pyspdxtools -i sbom.json --graph -o sbom``</p> <p>You can use this site, Graphviz Visual Editor to convert the sbom.dot file to an SVG image. For this project the filename is spdx.svg.</p>"},{"location":"intro/#security-policy","title":"Security Policy","text":"<p>Click here to open the Security Policy</p>"},{"location":"usage/","title":"Using the Script","text":"<p>There are a few steps that need to be completed before starting the discovery process:</p> <ul> <li>Create a device inventory file</li> <li>Make changes to the procurve-config-file.txt file (if needed)</li> <li>Decide how you want store the password</li> <li>Update the mac.txt file to match the format of the switches</li> </ul>"},{"location":"usage/#create-the-device-inventory-file","title":"Create the device inventory file","text":"<p>You must create a csv file that contains the following:</p> <pre><code>switch ip\nnetmiko vendor_id\nswitch hostname\nusername\nformat that the device needs to output mac addresses per interface\n</code></pre> <p>The supported Netmiko vendor_ids are:</p> <pre><code>hp_procurve\ncisco_ios\ncisco_xe\ncisco_nx\naruba_cx\n</code></pre> <p>The format for each line in the <code>device-inventory</code> file is:</p> <p><code>ip_address,vendor_id,hostname,user,command to display mac addresses per intf</code></p> <p>Here is an example of a <code>device-inventory</code> file:</p> <pre><code>192.168.10.52,hp_procurve,Procurve-2920-24,mhubbard,show mac-addre\n192.168.10.253,cisco_xe,3850,mhubbard,show mac addr int\n192.168.10.54,cisco_xe,4500,mhubbard,show mac addr int\n192.168.10.15,cisco_ios,2960s,mhubbard,show mac addr int\n</code></pre> <p>In this example, there are hp_procurve, cisco_xe and cisco_ios devices. You can have as many devices in the file as you need. I have had as many 50 in one file.</p> <p>Create one line for every switch that you want to process.</p> <p>You can use either a spreadsheet program or a text editor to create the inventory file but it must have a \".csv\" file extension. If you use vscode, there is a plugin called Rainbow CSV that allows you to work with csv files in vscode. It also allows you to use SQL syntax to query the file. Very nice if the file gets to be long. Below is a screenshot to the Rainbow CSV <code>RBQL Console</code>. RBQL is short for Rainbow Query Language.</p> <p></p> <p>Rainbow CSV also has an <code>align</code> feature that makes it easier to read the columns. Here is a screenshot of a device file opened in vs code with Rainbow csv:</p> <p></p> <p>Save the file as <code>device-inventory-&lt;site name&gt;.csv</code> in the root of the project folder.</p> <p>For example, <code>device-inventory-HQ.csv</code></p> <p>There is a sample file named device-inventory-area1.csv in the project. The site name is just a tag so that you can have as many device-inventory files as you need. At a large customer this might be the MDF and then a series of IDFs.</p>"},{"location":"usage/#csvlens","title":"CSVLENS","text":"<p>There is also a great terminal tool called <code>csvlens</code>. It's an open source project on GitHub csvlens. It's cross platform and runs on Mac/Linux/Windows.</p>"},{"location":"usage/#install-on-maclinux","title":"Install on Mac/Linux","text":"<p>Homebrew is easiest way to install</p> <p><code>brew install csvlens</code> and your are done.</p> <p>If you don't use homebrew you can go to the releases page, download the tarball and install using:</p> <pre><code>tar xvf csvlens-x86_64-unknown-linux-gnu.tar.xz\ncd csvlens-x86_64-unknown-linux-gnu\nsudo mv csvlens /usr/bin\n</code></pre> <p>The mv command <code>moves</code> csvlens to `/usr/bin' so that you can call it from anywhere.</p> <p>The problem with installing csvlens this way is that you don't get automatic updates. This is a very active project and updates usually add nice features. You will have to manually download the tar file and repeat the process.</p> <p>Version 0.13.0 release notes:</p> <pre><code>    Add --color-columns to display each column in a different color (#39)\n    Add --prompt to show a custom prompt message in the status bar (#135)\n    Expose freeze columns option in library usage (#124 by @jqnatividad)\n    Improve visibility of line numbers and borders\n    Add aarch64 release targets (#55)\n</code></pre> <p>The --color-columns is a nice addition. To view the device-inventory-home.csv file with colored columns use <code>csvlens --no-headers --color-columns device-inventory-home.csv</code>.</p>"},{"location":"usage/#create-an-alias-for-csvlens","title":"Create an alias for csvlens","text":"<p>You can create an alias in your ~/.bashrc or ~/.zshrc file:</p> <pre><code># csvlens with colored columns\nalias csvlens='()csvlens --no-headers --color-columns $1'\n</code></pre> <p>Then use <code>csvlens device-inventory-home.csv</code> to get colors and no header.</p> <p></p>"},{"location":"usage/#install-csvlens-on-windows","title":"Install CSVLENS on Windows","text":"<p><code>winget install --id YS-L.csvlens</code></p> <p>It's a little more of a challenge to on Windows to create the alias. You will need to use PowerShell as your terminal and update the profile text file. First, open a powershell terminal. I recommend installing the Windows Terminal so that you can have cmd.exe, PowerShell, and WSL terminals in one place. Then enter <code>notepad $PROFILE</code> to open the PowerShell profile for editing. Paste this into the bottom of the text file:</p> <pre><code># Simplified function to run csvlens with specified arguments using @args\nfunction Invoke-CsvLensWithArgs {\n    csvlens.exe --color-columns --no-headers @args\n}\n\n# Alias for the 'Invoke-CsvLensWithArgs' function (explicitly set to Global scope)\nSet-Alias -Name cl -Value Invoke-CsvLensWithArgs -Scope Global\n</code></pre> <p>Save and close the file. Then back in the PowerShell terminal enter:</p> <pre><code>echo $PROFILE\ntype $PROFILE\n. $PROFILE\n</code></pre> <p>This will:</p> <ul> <li>display the path to the <code>$PROFILE</code> file</li> <li>print the contents of the <code>$PROFILE</code> file</li> <li>reload the profile so that the alias works</li> </ul> <p>One big advantage to using Windows terminal with PowerShell is that it stores the history of your commands in a file. So you can close the terminal but not lose your history. PowerShell also comes with builtin aliases for several Linux commands like:</p> <ul> <li>cat - The Linux <code>cat</code> command to concatenate or display text files.</li> <li>clear - Clear the screen.</li> <li>cp - Linux copy command to copy files.</li> <li>echo - Echo text to the screen (stdout in Linux terms)</li> <li>ls - Linux <code>List Files</code> command</li> <li>mkdir - Linux Make Directory command</li> <li>mv - Linux move files command</li> <li>popd - Linux command to pop to the top level directory off the stack</li> <li>pushd - Linux command to push the current directory to the top of the stack</li> <li>pwd - Linux <code>Print Working Directory</code> command. Outputs the directory you are in.</li> <li>rm - Linux <code>Remove Files</code> command</li> </ul> <p>If you are creating bash scripts <code>popd</code> and <code>pushd</code> are useful. Having these aliases built in is great if you work on Mac, Linux and Windows since Mac/Linux share the same commands.</p>"},{"location":"usage/#install-bat-on-windows","title":"Install Bat on Windows","text":"<p>As long as we are installing cool utilities on Windows we should install <code>bat</code>. Bat is like <code>cat</code> on Linux but works on Windows also.</p> <p><code>winget install sharkdp.bat</code></p> <p>After that you can do <code>bat device-inventory-home.csv</code> and get a nice formatted, colored output. The advantage to <code>bat</code> over <code>csvlens</code> is that it works with any text file.</p>"},{"location":"usage/#password","title":"Password","text":"<p>Handling credentials is always an area of concern. The script supports two methods:</p> <ul> <li>Create an environment variable \"cyberARK\" and save the password to the variable.</li> <li>include <code>-p 1</code> on the command line to be prompted for the password</li> </ul> <p>Neither method is perfect but using either the environment variable or being prompted is more secure than having a csv file with plaintext passwords in it.</p>"},{"location":"usage/#creating-an-environment-variable","title":"Creating an Environment Variable","text":"<p>On Windows you use control panel to create a \"user environment variable\". You can follow these instructions user environment variables. You have to log out and log in again to make the environment variable active.</p> <p>Set environment variable on macOS/Linux</p> <p>From the terminal that you will run the script in <code>export cyberARK=&lt;Password&gt;</code>, for example <code>export cyberARK=Sup3rs3cr3t</code>. You have to do the export in the terminal that the script will be run in. If you are using vscode and debugging in vscode, that means the vscode terminal.</p>"},{"location":"usage/#being-prompted-for-the-password","title":"Being prompted for the password","text":"<p>This is easier than setting up environment variable. You simply add <code>-p 1</code> to the command line.</p> <p>For example, to run the script for a site named HQ:</p> <p><code>python3 config-pull.py -s HQ -p 1</code></p> <p>When you press enter, you will see \"Input the Password:\" on the command line. Enter the password and press [enter]</p>"},{"location":"usage/#update-the-config-filetxt-file","title":"Update the -config-file.txt file <p>This file contains all of the <code>show commands</code> that will be sent to the switches. The project includes sample files for hp_procurve, cisco_ios, and cisco_xe switches. The sample files have over 50 commands in them, including many that may not apply to the customer:</p> <ul> <li>show lacp peer</li> <li>show lacp local</li> <li>show lacp mad-passthrough</li> <li>show dhcp-server binding</li> <li>show dhcp-server pool</li> </ul> <p>If you don't need them for a particular customer you can just open the file and delete any that you don't need or add any that you do need. The goal is to have all the data needed to satisfy the Change Request requirements.</p> <p>The script looks for <code>&lt;vendor-id&gt;-config-file.txt</code>. You have to use that exact format. Since the script supports the following Netmiko vendor_ids:</p> <ul> <li>hp_procurve</li> <li>cisco_ios</li> <li>cisco_xe</li> <li>cisco_nx</li> <li>aruba_cx</li> </ul> <p>The config files will be named:</p> <ul> <li>hp_procurve-config-file.txt</li> <li>cisco_ios-config-file.txt</li> <li>cisco_xe-config-file.txt</li> <li>cisco_nx-config-file.txt</li> <li>aruba_cx-config-file.txt</li> </ul>  <p>Warning</p> <p>On older switches, reading a lot of data can cause the CPU to go to 90% or higher! This will cause issues if OSPF or EIGRP is running and may cause the script to fail with a timeout. If this happens, remove some commands from the config-file and try again.</p>","text":""},{"location":"usage/#pulling-the-mac-address-table","title":"Pulling the mac address table","text":"<p>For pulling the mac-address table, which most customers want you to do before a cutover, I build an exclude statement using a regex to skip uplink ports. Here is an example for HPE Procurve that doesn't pull mac addresses for ports on modules A and B. These were uplinks on one of the switches that I developed the script on.</p> <p><code>show show mac-address | ex \"A|B\"</code></p> <p>In the example, the <code>|</code> symbol means logical OR. This works because the switch displays the mac address in lower case.</p> <pre><code> show mac-address | ex \"A|B\"\n\n  ----------------- ------------------------------- ----\n  00c0b7-f4b43a     C4                              1\n  282986-40a427     H24                             1\n</code></pre> <p>Notice that port C4 has a lowercase a and b in the address and port H24 has a lowercase a. Since the regex is case sensitive this works.</p> <p>On a non-modular switch you can't use:</p> <pre><code>sh mac-address | exclude 24|25\n\n Status and Counters - Port Address Table\n\n  MAC Address   Port    VLAN\n  ------------- ------- ----\n  00e04c-360348 5       10\n</code></pre> <p>Because port 11 has <code>25</code> in the mac address</p> <p><code>b00cd1-372591 11      10</code></p> <p>And was excluded from the output.</p> <p>Here is a regex that will match only port 24 so that you can exclude port 24.</p> <pre><code>show mac-address | exclude \" [0]*24[ ]+\"\n\n Status and Counters - Port Address Table\n\n  MAC Address   Port    VLAN\n  ------------- ------- ----\n  bc9fe4-c342ca 12      1\n  00e04c-360348 5       10\n</code></pre> <p>You can also use the regex \"|\" OR symbol:</p> <pre><code>show mac-address | exclude \" [0]*5|24[ ]+\"\n\n Status and Counters - Port Address Table\n\n  MAC Address   Port    VLAN\n  ------------- ------- ----\n  bc9fe4-c342ca 12      1\n</code></pre> <p>Notice that if you wanted to exclude port 1, 2, 3, or 4,  you would add a space after the number. Otherwise the regex would match 11, 21, 31, 41.</p> <p>Or just forget the regex! The goal is to not include mac-addresses from uplinks and system MACs. But you would need to know what ports to exclude ahead of time. You can just dump the whole table. The only time I have seen this cause a problem was on a Cisco 6509 core that had six 48 port blades and several IDFs connected to the fiber card. There are a lot of mac in that table. The script worked but it took a while!</p> <p>I use this site to test/develop regex expressions.</p>"},{"location":"usage/#cisco-ios-mac-address-table-exclude","title":"Cisco IOS mac address table exclude","text":"<p>The Cisco IOS has this regex <code>show mac address-table | ex STATIC|Po|1/0/49</code></p> <p>This excludes ports with:</p> <ul> <li>STATIC</li> <li>Port Channels</li> <li>interface 1/0/49</li> </ul> <p>Or just forget the regex! The goal is to not include mac-addresses from uplinks and system MACs. But you would need to know what ports to exclude ahead of time. You can just dump the whole table. The only time I have seen this cause a problem was on a Cisco 6509 core that had six 48 port blades and several IDFs connected to the fiber card. There are a lot of mac in that table. The script worked but it took a while!</p>"},{"location":"usage/#cisco-xe-mac-address-table-exclude","title":"Cisco XE mac address table exclude","text":"<p><code>show mac address-table | ex Po|ffff.ffff.ffff|static</code></p> <p>Again, the goal is to exclude uplinks.</p>"},{"location":"usage/#run-the-discovery-script","title":"Run the discovery script <p>Now that the project is set up and the inventory file is created, you can run the script. Make sure you are in the Discovery directory and run:</p> <pre><code>source bin/activate\n</code></pre> <p>or</p> <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <p>To activate the the virtual environment.</p>","text":""},{"location":"usage/#what-options-are-available","title":"What options are available","text":"<p>You can run the script with -h to get help:</p> <pre><code>python3 procurve_Config_pull.py -h\n\n\nusage: procurve_Config_pull.py [-h] [-e EVENT] [-l LOGGING] [-p PASSWORD] [-s SITE] [-t TIMEOUT]\n\n-s site, -l 1 create log.txt, -p 1 prompt for password, -t 1-9 timeout, -e W,I,M,D,E to pull logs\n\noptions:\n  -h, --help            show this help message and exit\n  -e EVENT, --event EVENT\n                        -e W,I,M,D,E to pull switch logs\n  -l LOGGING, --logging LOGGING\n                        use -l 1 to enable ssh logging\n  -p PASSWORD, --password PASSWORD\n                        use -p 1 to be prompted for password\n  -s SITE, --site SITE  Site name - ex. HQ\n  -t TIMEOUT, --timeout TIMEOUT\n                        use -t 1-9 to set timeout\n(Discovery)\n</code></pre>"},{"location":"usage/#what-do-the-arguments-do","title":"What do the arguments do","text":"<p>The only required argument is <code>-s site</code>. This references the device-inventory file.</p>"},{"location":"usage/#collecting-switch-logs","title":"Collecting switch logs","text":"<p>Reviewing switch logs before a cut over can help you understand the health of the network. For example, you may find OSPF neighbors bouncing or an STP issue. Obviously if the network is large you can't review every switch in detail. But looking at key switches such as cores and distribution is worth a few minutes.</p> <p>Using <code>grep</code> you can parse hundreds of logs in a matter of seconds. The log files are saved to the CR-data folder. If you cd to the CR-data folder you can run this <code>grep</code> command to find lacp issues from any switch:</p> <pre><code>grep -Eir 'Blocked by LACP'\ntest-CL-2930-48-1-log-1.txt:I 02/02/24 17:20:55 00435 ports: port 22 is Blocked by LACP\n</code></pre> <p>Or check STP:</p> <pre><code>grep -Eir 'stp:'\nProcurve-2920-24-CR-data.txt:I 01/10/24 19:01:57 03816 stp: VLAN 850 - Root changed from 32768: (this device)\n</code></pre> <p>I can't go into everything you should look for, but with some practice you will look like a genius finding intermittent issues on the customer's network!</p>"},{"location":"usage/#procurve-logs","title":"Procurve logs","text":"<p>The procurve switches allow you to pull five different types of logs:</p> <ul> <li>Warning (W) - This log contains warning messages</li> <li>Informational (I) - This log can grow very large and may need a large timeout value. If you have a lot of switches to discovery and they have large informational logs you may want to skip them.</li> <li>Major (M) - This log contains major messages</li> <li>Debug (D) - This log contains debug messages</li> <li>Error (E) - This log contains error messages</li> </ul> <p>If you want to pull logs from the switch add <code>-e</code> and the type of log. You can collect 1 or all 5. Separate the values with a comma. For example:</p> <p><code>-e W,I,M,D,E</code></p> <p>If you use <code>-e W</code> the script will send <code>show logging -r -W</code></p> <p>The reason I added the ability to collect individual logs is that I had time out issues sending <code>show logging -r</code> because the Procurve switches have a lot of storage for logs. This happened at a customer with large a stack of 2930s and an intermittent connectivity issue.</p> <p>But, it turned out to be useful because informational logs are a lot of noise. Being able to narrow down and look at just Warning or Major logs is nice.</p>"},{"location":"usage/#cisco-logs","title":"Cisco Logs","text":"<p>Cisco doesn't support all the options that the procurve does. If you want to collect logs on a cisco use <code>-e 1</code>. This will send <code>show logging</code> to the switch.</p> <p>I haven't run into the timeout issue on Cisco switches. I think this is because by default Cisco logging is set to only 4096 and most engineers don't change it.</p> <p>Using <code>grep</code> you can parse hundreds of logs in a matter of seconds. The log files are saved to the CR-data folder. If you cd to the CR-data folder you can run this <code>grep</code> command to find stacking messages from any switch:</p> <pre><code>grep -Eir 'stack_mgr:'\nLab_3850-log-1.txt:*Jul 13 19:33:52.175: %STACKMGR-4-SWITCH_ADDED: Switch 2 R0/0: stack_mgr: Switch 2 has been added to the stack.\n</code></pre> <p>Find <code>connected</code> ports</p> <p>Customers often ask how many active ports are on a switch. This grep statement will return the port from the <code>show interface status | i connected</code> command:</p> <p><code>grep \"connected\" JC-MDF-4-CR-data.txt | awk '{print $1}' | sort | uniq | sort -t '/' -k1,1 -k2,2n -k3,3n</code></p> <p>Output</p> <pre><code>Gi1/0/1\nGi1/0/2\nGi1/0/3\nGi1/0/5\nGi1/0/9\nGi1/0/10\nGi1/0/12\nGi1/0/16\nGi1/0/17\nGi1/0/21\nGi1/0/25\n</code></pre> <p>\ud83d\udccb Explanation of the Command</p> <ul> <li>grep \"connected\" JC-MDF-4-CR-data.txt: This filters lines containing \"connected\" from the file.</li> <li>awk '{print $1}': This extracts the first column (the interface names).</li> <li>sort: This sorts the interface names, ensuring that duplicates are adjacent.</li> <li>uniq -c: This counts the occurrences of each unique interface name.</li> <li>sort -t '/' -k1,1 -k2,2n -k3,3n: This sorts the counted output correctly based on the interface name structure.</li> </ul> <p>If you want to return the entire line from the <code>show interface status | i connected</code> command use this grep:</p> <p><code>grep \"connected\" JC-MDF-4-CR-data.txt | sort | uniq | sort -t '/' -k1,1 -k2,2n -k3,3n</code></p> <p>Output</p> <pre><code>Gi1/0/1   &lt; Uplink to SonicW connected    777        a-full a-1000 10/100/1000BaseTX\nGi1/0/2   &lt; Uplink to SonicW connected    20         a-full a-1000 10/100/1000BaseTX\nGi1/0/3   &lt; Uplink to SonicW connected    100        a-full a-1000 10/100/1000BaseTX\nGi1/0/5   &lt; Uplink to SonicW connected    778        a-full a-1000 10/100/1000BaseTX\nGi1/0/9   &lt; Voice Server &gt;   connected    90         a-full a-1000 10/100/1000BaseTX\nGi1/0/10  &lt; Voice Server &gt;   connected    90         a-full a-1000 10/100/1000BaseTX\nGi1/0/12  &lt; Safelok SRV 10.1 connected    100        a-full a-1000 10/100/1000BaseTX\nGi1/0/16  &lt; BacTalk Port &gt;   connected    778        a-half  a-100 10/100/1000BaseTX\nGi1/0/17  &lt; Voice Network &gt;  connected    90         a-full a-1000 10/100/1000BaseTX\nGi1/0/21  &lt; HIS &gt;            connected    780        a-full a-1000 10/100/1000BaseTX\nGi1/0/25  &lt; Uplink to 4500x  connected    trunk      a-full a-1000 1000BaseLX SFP\nGi1/0/25  &lt; Uplink to 4500x  connected    trunk      a-full a-1000 1000BaseLX SFP\n</code></pre>"},{"location":"usage/#setting-the-password","title":"Setting the Password","text":"<p>If you want to be prompted for a password add <code>-p 1</code>. If you don't use -p 1 you must set an environment variable <code>cyberARK</code> with the password. That is covered above in the \"password\" section.</p>"},{"location":"usage/#ssh-logging","title":"SSH Logging","text":"<p>If you want to enable ssh logging add <code>-l 1</code>. You would do that to troubleshoot if you are getting \"time out\" errors when the script tries to connect to a switch. It does not log anything from the switch.</p>"},{"location":"usage/#timeout","title":"Timeout","text":"<p>You can modify the timeout value using  <code>-t</code>. Note: the number sets the timeout value in 100s of seconds. If you use <code>-t 2</code> it will wait up to 200 seconds for the operation to complete.</p>"},{"location":"usage/#argument-examples","title":"Argument Examples","text":"<p>The minimum is to use -s for the site:</p> <p><code>python3 config-pull.py -s HQ</code></p> <p>To include the Warning log from HPE Procurve switches:</p> <p><code>python3 config-pull.py -s HQ -e W</code></p> <p>To include all logs and set timeout to 2:</p> <p><code>python3 config-pull.py -s HQ -e W,I,M,D,E -t 2</code></p> <p>To be prompted for a password:</p> <p><code>python3 config-pull.py -s HQ -p 1</code></p> <p>Note</p> <p>you may have to use python instead of python3 depending on your OS.</p> <p>I recommend running the script on one network switch the first time instead of a long list of switches. That will let you see the content of the show commands and make changes if needed before spending time running it on a long list of switches.</p> <p>The files will be saved in the following directories:</p> <ul> <li>CR-data - files that are ready for viewing</li> <li>Interface - files that need further processing</li> <li>Failure-Logs</li> <li>port-maps - files for creating port maps</li> <li>Running - The \"show running structured\" output for each switch</li> </ul> <p>If you are having timeout or authentication issues, enable logging. Here is a sample output of the log.txt file that netmiko creates:</p> <pre><code>DEBUG:paramiko.transport:starting thread (client mode): 0xb4b346d0\nDEBUG:paramiko.transport:Local version/idstring: SSH-2.0-paramiko_3.4.0\nDEBUG:paramiko.transport:Remote version/idstring: SSH-2.0-Mocana SSH 6.3\nINFO:paramiko.transport:Connected (version 2.0, client Mocana)\nDEBUG:paramiko.transport:=== Key exchange possibilities ===\nDEBUG:paramiko.transport:kex algos: ecdh-sha2-nistp256, ecdh-sha2-nistp384, ecdh-sha2-nistp521, diffie-hellman-group-exchange-sha256, diffie-hellman-group14-sha1\nDEBUG:paramiko.transport:server key: rsa-sha2-512, rsa-sha2-256, ssh-rsa\nDEBUG:paramiko.transport:client encrypt: aes256-ctr, rijndael-cbc@lysator.liu.se, aes192-ctr, aes128-ctr\nDEBUG:paramiko.transport:server encrypt: aes256-ctr, rijndael-cbc@lysator.liu.se, aes192-ctr, aes128-ctr\nDEBUG:paramiko.transport:client mac: hmac-sha1-96, hmac-sha1\nDEBUG:paramiko.transport:server mac: hmac-sha1-96, hmac-sha1\nDEBUG:paramiko.transport:client compress: none\nDEBUG:paramiko.transport:server compress: none\nDEBUG:paramiko.transport:client lang: &lt;none&gt;\nDEBUG:paramiko.transport:server lang: &lt;none&gt;\nDEBUG:paramiko.transport:kex follows: False\nDEBUG:paramiko.transport:=== Key exchange agreements ===\nDEBUG:paramiko.transport:Kex: ecdh-sha2-nistp256\nDEBUG:paramiko.transport:HostKey: rsa-sha2-512\nDEBUG:paramiko.transport:Cipher: aes128-ctr\nDEBUG:paramiko.transport:MAC: hmac-sha1\nDEBUG:paramiko.transport:Compression: none\nDEBUG:paramiko.transport:=== End of kex handshake ===\nDEBUG:paramiko.transport:kex engine KexNistp256 specified hash_algo &lt;built-in function openssl_sha256&gt;\nDEBUG:paramiko.transport:Switch to new keys ...\nDEBUG:paramiko.transport:Adding ssh-rsa host key for 10.112.254.60: b'47708eeea6cbecf20b5916d675feca3d'\nDEBUG:paramiko.transport:userauth is OK\nINFO:paramiko.transport:Auth banner: b'******************************************************************************\\nThis system is the property of Michael Hubbard.\\n\\nUNAUTHORIZED ACCESS TO THIS DEVICE IS PROHIBITED.\\n\\nYou must have explicit permission to access this device.\\n\\nAll activities performed on this device are logged.\\nAny violations of access policy will result in disciplinary action.\\n****************************************************************************** \\n\\n'\nINFO:paramiko.transport:Authentication (password) successful!\n</code></pre> <p>Here is a sample output from running the script:</p> <pre><code>config_pull.py -s area1 -e W\n\n\n-------------------------------------------------\nReading devices from: device-inventory-area1.csv\n----------------------------------------------------------\n01/21/2024, 19:02:50 Connecting to switch Procurve-2920-24\n----------------------------------------------------------\n\nExec time: 0:00:01.279461\n\nCould not connect to Procurve-2920-24 at 192.168.10.50. The Credentials failed.  Remove it from the device inventory file\n----------------------------------------------------------\n01/21/2024, 19:02:51 Connecting to switch Procurve-2920-48\n----------------------------------------------------------\n\nHP-2920-24G-PoEP#\n\n--------------------------------------------------------\nprocessing procurve-config-file.txt for Procurve-2920-48\n--------------------------------------------------------\nprocessing show logging -W for Procurve-2920-48\n--------------------------------------------------------\nWriting show logging -W commands to /home/mhubbard/04_Tools/Discovery/CR-data/Procurve-2920-48-log-W.txt\n--------------------------------------------------------\ncollecting show interface for Procurve-2920-48\n--------------------------------------------------------\ncollecting show system for Procurve-2920-48\n--------------------------------------------------------\ncollecting show cdp detail for Procurve-2920-48\n--------------------------------------------------------\ncollecting show interfaces brief for Procurve-2920-48\n--------------------------------------------------------\ncollecting show lldp neighbors for Procurve-2920-48\n--------------------------------------------------------\ncollecting show mac address for Procurve-2920-48\n--------------------------------------------------------\ncollecting show arp for Procurve-2920-48\n--------------------------------------------------------\nCollecting show running-config from Procurve-2920-48\n--------------------------------------------------------\nWriting show commands to /home/mhubbard/04_Tools/Discovery/CR-data/Procurve-2920-48-CR-data.txt\n-------------------------------------------------\nWriting MAC addresses to /home/mhubbard/04_Tools/Discovery/port-maps/data/Procurve-2920-48-mac-address.txt\n-------------------------------------------------\nWriting ARP data to /home/mhubbard/04_Tools/Discovery/port-maps/data/Procurve-2920-48-arp.txt\n-------------------------------------------------\nWriting show run to /home/mhubbard/04_Tools/Discovery/port-maps/data/Procurve-2920-48-arp.txt\n-------------------------------------------------\nWriting interfaces json data to /home/mhubbard/04_Tools/Discovery/Interface/Procurve-2920-48-system.txt\n-------------------------------------------------\nWriting interfaces json data to /home/mhubbard/04_Tools/Discovery/Interface/Procurve-2920-48-interface.txt\n-------------------------------------------------\nWriting interfaces brief data to /home/mhubbard/04_Tools/Discovery/Interface/Procurve-2920-48-int_br.txt\n-------------------------------------------------\nWriting cdp neighbor data to /home/mhubbard/04_Tools/Discovery/Interface/Procurve-2920-48-cdp.txt\n-------------------------------------------------\nWriting show lldp data to /home/mhubbard/04_Tools/Discovery/Interface/Procurve-2920-48-lldp.txt\n\n-------------------------------------------------------\nSuccessfully created config files for Procurve-2920-48\n-------------------------------------------------------\n\nData collection is complete.\nTotal running time: 0.0 Hours 1.0 Minutes 44.67 Seconds\n</code></pre>"},{"location":"usage/#failure-to-connect-to-a-switch","title":"Failure to connect to a switch <p>If a switch does not respond, the credentials are incorrect, or the SSH version is 1, a message will be printed to the console, a log file with the hostname and a reason code is written to hte <code>Failure-log</code> folder and the script will continue processing the next switch.</p> <p>It's really disruptive to the discovery process if the script cannot connect to multiple switches. That means you have to fix the problem, create a new inventory file with just the failed switches, then rerun the script on the subset. I was doing a discovery at a customer with over 240 switches. They had a lot of configuration issues and username/password variations. I ended up with around 40 switches that I couldn't log into.</p>","text":""},{"location":"usage/#use-nmap-to-verify-switches-are-up","title":"Use nmap to verify switches are up","text":"<p>I recommend saving the switch IP addresses in a plain text file, one per line, and then using nmap to verify that ssh is working.</p>"},{"location":"usage/#the-process","title":"THe process","text":"<p>Create a new text file named <code>ip.txt</code>. If you are using vs code and the Rainbow csv extension you can simply run a query on the device-inventory file:</p> <p><code>select a1</code></p> <p>That will return all the IP addresses.</p> <p>At the bottom of vs code, click <code>query</code>.</p> <p></p> <p>When the query page opens, enter <code>select a1</code> and click <code>run</code>.</p> <p></p> <p>The query will return a list of IP addresses, 1 per line. Select all lines and paste them into ip.txt.</p> <pre><code>192.168.10.50\n192.168.10.52\n192.168.10.111\n192.168.10.230\n</code></pre> <p>Run nmap with these arguments:</p> <p><code>nmap -v -p 22 -iL ip.txt --reason -oN ip-dead.txt</code></p> <p>This tells nmap to use ip.txt for the target IP addresses, include the reason and save the output to ip-dead.txt.</p> <p>In this example only 3 devices are working:</p> <p><code>Nmap done at Sun Jan  7 20:05:46 2024 -- 4 IP addresses (3 hosts up) scanned</code></p> <p>If you don't get 100%, open <code>ip-dead.txt</code> and search for \"down\".</p>"},{"location":"usage/#use-nmap-to-verify-the-credentials","title":"Use nmap to verify the credentials","text":"<p>There isn't a simple way to verify that the credentials will work. If you have permission to run the nmap ssh-brute script you can verify using:</p> <p><code>nmap -p 22 --script ssh-brute --script-args userdb=user.lst,passdb=pass.lst -iL ip.txt</code></p> <p>Put your username in user.lst and your password in pass.lst.</p> <p>You will get back a report for each device:</p> <pre><code>Nmap scan report for 192.168.10.52\nHost is up (0.0033s latency).\n\nPORT   STATE SERVICE\n22/tcp open  ssh\n| ssh-brute:\n|   Accounts:\n|     sw_admin:Sup3rS3cr3t - Valid credentials\n|_  Statistics: Performed 2 guesses in 2 seconds, average tps: 1.0\n\nNmap scan report for 192.168.10.111\nHost is up (0.0028s latency).\n\nPORT   STATE SERVICE\n22/tcp open  ssh\n| ssh-brute:\n|   Accounts: No valid accounts found\n|_  Statistics: Performed 2 guesses in 4 seconds, average tps: 0.5\n</code></pre> <p>Then use <code>grep -Eir -b6 \"No valid\" accounts.txt</code> to find the devices with no valid accounts.</p> <p>Grep Arguments:</p> <ul> <li>E - extended</li> <li>i - case-insensitive</li> <li>r - recursive</li> <li>-b6 - show 6 lines before the match</li> </ul>"},{"location":"usage/#building-a-list-of-switches","title":"Building a list of switches <p>Not all customers will have a clean list of switch IP addresses and host names. If there is a management network you may be able to look at the arp table and pull out the switches. As a last resort you can use the following process to build a list of switches.</p> <p>Run this nmap command to find devices with ssh and snmp open. Most devices that have ssh and snmp open are switches. You may have to do some additional filtering.</p> <p><code>sudo nmap -sU -sS -T4 -sC -p U:161,T:22 -oA procurve-scan -n -Pn --open --stylesheet https://raw.githubusercontent.com/honze-net/nmap-bootstrap-xsl/master/nmap-bootstrap.xsl &lt;target ips&gt;</code></p>  <p>Note</p> <p>The stylesheet is from honze-net-nmap-bootstrap-xsl. This is a repository for creating nmap reports. Well worth a look.</p>  <p>!!! warning Failed to open normal output file procurve-scan.nmap for writing: Permission denied (13)     If you installed <code>nmap</code> using a snap on Ubuntu you will not be able to write a file as root to a folder you own.</p> <p>If you receive the <code>Permission denied (13)</code> message, add <code>/tmp/</code> to the filename:</p> <p><code>sudo nmap -sU -sS -T4 -sC -p U:161,T:22 -oA /tmp/procurve-scan -n -Pn --open --stylesheet https://raw.githubusercontent.com/honze-net/nmap-bootstrap-xsl/master/nmap-bootstrap.xsl &lt;target ips&gt;</code></p> <p>The <code>-oA switch-scan</code> argument will create the following files:</p> <ul> <li>procurve-scan.xml - a standard XML file with the xsl link embedded</li> <li>procurve-scan.nmap - an nmap format file</li> <li>procurve-scan.gnmap - a greppable nmap format file</li> </ul> <p>The files will be owned by the root account since we need <code>sudo</code> for the UDP scan. Here are the permissions:</p> <pre><code>$ ls -l procurve-scan*\n-rw-r--r-- 1 root root  477 2024-01-14 17:13 procurve-scan.gnmap\n-rw-r--r-- 1 root root  926 2024-01-14 17:13 procurve-scan.nmap\n-rw-r--r-- 1 root root 3.6K 2024-01-14 17:13 procurve-scan.xml\n</code></pre> <p>Run the following to take ownership of the files:</p> <p><code>sudo chown $USER procurve-scan*</code></p> <p>The results:</p> <pre><code>ls -l procurve-scan*\n-rw-r--r-- 1 mhubbard root  477 2024-01-14 17:13 procurve-scan.gnmap\n-rw-r--r-- 1 mhubbard root  926 2024-01-14 17:13 procurve-scan.nmap\n-rw-r--r-- 1 mhubbard root 3.6K 2024-01-14 17:13 procurve-scan.xml\n</code></pre> <p>The output will look something like this:</p> <pre><code>sudo nmap -sU -sS -T4 -sC -p U:161,T:22 -oA procurve-scan -n -Pn --open --stylesheet [nmap-bootstrap.xsl](https://raw.githubusercontent.com/honze-net/nmap-bootstrap-xsl/master/nmap-bootstrap.xsl) 192.168.10.52\nHost discovery disabled (-Pn). All addresses will be marked 'up' and scan times will be slower.\nStarting Nmap 7.91 ( https://nmap.org ) at 2024-01-14 17:09 PST\nNmap scan report for 192.168.10.52\nHost is up (0.0032s latency).\n\nPORT    STATE         SERVICE\n22/tcp  open          ssh\n| ssh-hostkey:\n|_  1024 cb:a8:d6:c7:da:bd:67:53:91:8c:c0:1b:49:d1:a1:2d (DSA)\n| ssh-os:\n|_  SSH Banner: SSH-2.0-Mocana SSH 6.3\\x0D\n161/udp open|filtered snmp\n| snmp-info:\n|   enterprise: Hewlett-Packard\n|   engineIDFormat: unknown\n|   engineIDData: 000098f2b3fe8880\n|   snmpEngineBoots: 108\n|_  snmpEngineTime: 5h40m26s\nMAC Address: 98:F2:B3:FE:88:80 (Hewlett Packard Enterprise)\n\nHost script results:\n|_smbv2-enabled: ERROR: Script execution failed (use -d to debug)\n\nNmap done: 1 IP address (1 host up) scanned in 15.03 seconds\n</code></pre> <p>The \"SSH Banner: SSH-2.0-Mocana SSH 6.3\" is the ssh server that is running on the procurve switch. Over the years HPE has used different ssh servers but this banner will help identify Procurve switches.</p> <p>Let's look at the contents of the procurve-scan.gnmap file:</p> <pre><code># Nmap 7.91 scan initiated Sun Jan 14 17:13:39 2024 as: nmap -sU -sS -T4 -sC -p U:161,T:22 -oA procurve-scan -n -Pn --open --stylesheet https://raw.githubusercontent.com/honze-net/nmap-bootstrap-xsl/master/nmap-bootstrap.xsl 192.168.10.52\nHost: 192.168.10.52 ()  Status: Up\nHost: 192.168.10.52 ()  Ports: 22/open/tcp//ssh///, 161/open|filtered/udp//snmp//Hewlett-Packard SNMPv3 server/\n# Nmap done at Sun Jan 14 17:13:54 2024 -- 1 IP address (1 host up) scanned in 15.09 seconds\n</code></pre> <p>If you are on Mac/Linux/Windows WSL or have git bash (or MobaXterm) installed on Windows you can use grep to pull out a list of the switches from procurve-scan.gnmap file. Use the following grep/awk command:</p> <p><code>bash  grep -Eir  \"22/open/tcp//ssh///, 161/open|filtered/udp//snmp//\" procurve.gnmap | awk '{ print $2 }' 192.168.10.52</code></p> <p>The <code>grep</code> found just the \"ssh, snmp\" string and <code>awk</code> printed the data in column 2.</p>","text":""},{"location":"usage/#review-the-bootstrap-report","title":"Review the bootstrap report","text":"<p>The \"stylesheet\" argument creates an xsl file to format the XML file that the script creates. You will be able to right-click on the xml file and open it in Firefox to see a nicely formatted report. This isn't required, it's just nice extra and you can give it the customer as documentation. Here is a simple example from my home lab:</p> <p></p>"},{"location":"usage/#opening-the-report-in-a-chromium-based-browser","title":"Opening the report in a Chromium based browser","text":"<p>If you want to open the report in a Chromium browser you will need to do the following:</p> <ul> <li>Open this page in Chrome/Edge</li> <li>Paste the text from procurve-scan.xml into \"Option 1: Copy-paste your XML document here\"</li> <li>Open nmap-bootstrap-xsl in a text editor and on line 8, delete -  <code>doctype-system=\"about:legacy-compat\"</code></li> <li>Paste the text into \"Option 2: Option 1: Copy-paste your XSL document here\"</li> <li>click <code>Transform XML</code></li> <li>Save the new text as procurve-scan.html. You lose a little bit of the report but it's still usable.</li> </ul>"},{"location":"usage/#alternative-ways-to-view-the-report-in-a-chromium-browser","title":"Alternative ways to view the report in a Chromium browser","text":"<p>The URL restriction occurs because the xsl file comes from an https server (github) and the file is on disk. If you use \"settings, Developer tools, console\", you will see this message:</p> <pre><code>procurve-scan.xml:3  Unsafe attempt to load URL\nhttps://raw.githubusercontent.com/honze-net/nmap-bootstrap-xsl/master/nmap-bootstrap.xsl\nfrom frame with URL\nfile:///home/mhubbard/04_Tools/Discovery/procurve-scan.xml.\n'file:' URLs are treated as unique security origins.\n</code></pre>"},{"location":"usage/#use-chrome-or-edge-browser-with-the-allow-allow-file-access-from-files-flag","title":"Use Chrome or edge browser with the allow --allow-file-access-from-files flag","text":"<p>Chromium based browsers provide a flag to allow local file access. This is a quick way to view the report. But keep in mind that there is a security risk if you don't close the browser after reviewing the report because it will open files without a warning.</p> <p>On Linux</p> <p>Navigate to the Chrome folder. On a debian based system this is <code>/opt/google/chrome</code>. Then start chrome using the following command:</p> <pre><code>cd /opt/google/chrome\n$ ./chrome --allow-file-access-from-files\n</code></pre> <p>Now you can open procurve.html in Chrome and view the report. If you use this feature often, you can create an alias in the <code>~/.zshrc</code> file</p> <pre><code># start chrome and allow local file read\nalias chrome-local='cd /opt/google/chrome;./chrome --allow-file-access-from-files'\n</code></pre> <p>On Windows</p> <p>You can copy this Chrome shortcut to the desktop and add the flag to the \"Target\" section:</p> <p><code>\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\" --allow-file-access-from-files</code></p> <p>Use the new shortcut to open procurve.html in chrome and view the report. Again, close the browser after you are finished with the report to eliminate the security risk.</p>"},{"location":"usage/#use-firefox","title":"Use Firefox","text":"<p>To use firefox:</p> <pre><code>Type \"about:config\" in the Firefox address bar\nSearch for \"security.fileuri.strict_origin_policy\"\nChange the setting to \"false\"\n</code></pre> <p>Now you can open procurve.html in Firefox and view the report. Don't forget to set security.fileuri.strict_origin_policy back to false when you are done.</p>"},{"location":"usage/#use-a-local-http-server","title":"Use a local http server","text":"<p>You can use the xsl file, nmap-bootstrap.xsl, that comes from cloning the repository. The drawback to this is that if you want to share the report, you have to include the xsl file.</p> <p>Change the nmap command to:</p> <pre><code>nmap -sU -sS -T4 -sC -p U:161,T:22 -oA procurve-scan -n -Pn --open --stylesheet nmap-bootstrap.xsl 192.168.10.52\n</code></pre> <p>Now spin up an http server using python:</p> <p><code>python3 -m http.server 8000</code></p> <p>Open a Chromium based browser and enter:</p> <p><code>http://localhost:8000/procurve-scan.xml</code></p> <p>The report will open and not be a limited version.</p> <p>Learning to use the python http server is a good skill. For example, if you have Aruba APs running in IAP mode and there are a mix of models you have to use http to upgrade them. This method works great on a laptop.</p>"},{"location":"usage/#references","title":"References","text":"<ul> <li>XSL Transformer - XSLT</li> <li>Restrictions on File Urls</li> <li>Transform XML+XSLT to plain html so that it loads without blocking</li> <li>Enabling Internet Explorer Mode in Microsoft Edge</li> <li>nmap-bootstrap-xsl</li> </ul>"},{"location":"usage/#emoji-codes-used-in-the-panel-function","title":"Emoji codes used in the panel function <p>If you want to expand on the script or change the emojis:</p>","text":""},{"location":"usage/#emoji-codes-for-status-panels","title":"Emoji Codes for Status Panels    Purpose Emoji Unicode Code Description     Success \u2705 <code>\\u2705</code> Checkmark   Error / Failure \u274c <code>\\u274C</code> Cross mark   Warning \u26a0\ufe0f <code>\\u26A0\\uFE0F</code> Warning sign   Info / Notice \u2139\ufe0f <code>\\u2139\\uFE0F</code> Info symbol   Timeout / Wait \u23f1\ufe0f <code>\\u23F1\\uFE0F</code> Stopwatch   Processing / Running \ud83d\udd04 <code>\\u1F501</code> Clockwise arrows   Connecting \ud83d\udd0c <code>\\u1F50C</code> Plug   Save / Write \ud83d\udcbe <code>\\u1F4BE</code> Floppy disk   Search / Discovery \ud83d\udd0d <code>\\u1F50D</code> Magnifying glass   Network \ud83c\udf10 <code>\\u1F310</code> Globe   Firewall / Security \ud83d\udd25 <code>\\u1F525</code> Flame   DNS / Naming \ud83c\udff7\ufe0f <code>\\u1F3F7\\uFE0F</code> Label   System Boot / Start \ud83d\ude80 <code>\\u1F680</code> Rocket   Power Off / Shutdown \u23fb <code>\\u23FB</code> Power symbol   Build / Compile \ud83d\udee0\ufe0f <code>\\u1F6E0\\uFE0F</code> Wrench and hammer","text":""}]}